{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anastasiarenata1/deeplearning/blob/main/LNN_with_Numpy_and_Softmax_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRQriJO6Rw4D"
      },
      "source": [
        "# Problem 4 - Regression\n",
        "\n",
        "Classification data from 2011 Million Song Challenge dataset to predict music year\n",
        "\n",
        "* Explore three shallow (linear) neural network models with different activation functions for this task.\n",
        "* Evaluate the model by rounding the output of your linear neural network and compute the mean squared error\n",
        "\n",
        "\n",
        "###1. Load and explore the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEErmxZU2EDU",
        "outputId": "65239bce-ff72-4979-d16f-b45f12585459"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-01 23:46:42--  https://archive.ics.uci.edu/ml/machine-learning-databases/00203/YearPredictionMSD.txt.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 211011981 (201M) [application/x-httpd-php]\n",
            "Saving to: ‘YearPredictionMSD.txt.zip’\n",
            "\n",
            "YearPredictionMSD.t 100%[===================>] 201.24M  31.1MB/s    in 7.0s    \n",
            "\n",
            "2023-03-01 23:46:49 (28.8 MB/s) - ‘YearPredictionMSD.txt.zip’ saved [211011981/211011981]\n",
            "\n",
            "Archive:  YearPredictionMSD.txt.zip\n",
            "  inflating: YearPredictionMSD.txt   \n"
          ]
        }
      ],
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00203/YearPredictionMSD.txt.zip\n",
        "!unzip YearPredictionMSD.txt.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jYGlyolcU0ai"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "BbPalayaR_Kz",
        "outputId": "7028cc01-4e00-4181-8f05-c800100b0544"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   target  timbre_avg_1  timbre_avg_2  timbre_avg_3  timbre_avg_4  \\\n",
              "0    2001      49.94357      21.47114      73.07750       8.74861   \n",
              "1    2001      48.73215      18.42930      70.32679      12.94636   \n",
              "2    2001      50.95714      31.85602      55.81851      13.41693   \n",
              "3    2001      48.24750      -1.89837      36.29772       2.58776   \n",
              "4    2001      50.97020      42.20998      67.09964       8.46791   \n",
              "\n",
              "   timbre_avg_5  timbre_avg_6  timbre_avg_7  timbre_avg_8  timbre_avg_9  ...  \\\n",
              "0     -17.40628     -13.09905     -25.01202     -12.23257       7.83089  ...   \n",
              "1     -10.32437     -24.83777       8.76630      -0.92019      18.76548  ...   \n",
              "2      -6.57898     -18.54940      -3.27872      -2.35035      16.07017  ...   \n",
              "3       0.97170     -26.21683       5.05097     -10.34124       3.55005  ...   \n",
              "4     -15.85279     -16.81409     -12.48207      -9.37636      12.63699  ...   \n",
              "\n",
              "   timbre_covar_69  timbre_covar_70  timbre_covar_71  timbre_covar_72  \\\n",
              "0         13.01620        -54.40548         58.99367         15.37344   \n",
              "1          5.66812        -19.68073         33.04964         42.87836   \n",
              "2          3.03800         26.05866        -50.92779         10.93792   \n",
              "3         34.57337       -171.70734        -16.96705        -46.67617   \n",
              "4          9.92661        -55.95724         64.92712        -17.72522   \n",
              "\n",
              "   timbre_covar_73  timbre_covar_74  timbre_covar_75  timbre_covar_76  \\\n",
              "0          1.11144        -23.08793         68.40795         -1.82223   \n",
              "1         -9.90378        -32.22788         70.49388         12.04941   \n",
              "2         -0.07568         43.20130       -115.00698         -0.05859   \n",
              "3        -12.51516         82.58061        -72.08993          9.90558   \n",
              "4         -1.49237         -7.50035         51.76631          7.88713   \n",
              "\n",
              "   timbre_covar_77  timbre_covar_78  \n",
              "0        -27.46348          2.26327  \n",
              "1         58.43453         26.92061  \n",
              "2         39.67068         -0.66345  \n",
              "3        199.62971         18.85382  \n",
              "4         55.66926         28.74903  \n",
              "\n",
              "[5 rows x 91 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5402f411-7e5e-4b50-bb46-1486cf4ba3ef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>timbre_avg_1</th>\n",
              "      <th>timbre_avg_2</th>\n",
              "      <th>timbre_avg_3</th>\n",
              "      <th>timbre_avg_4</th>\n",
              "      <th>timbre_avg_5</th>\n",
              "      <th>timbre_avg_6</th>\n",
              "      <th>timbre_avg_7</th>\n",
              "      <th>timbre_avg_8</th>\n",
              "      <th>timbre_avg_9</th>\n",
              "      <th>...</th>\n",
              "      <th>timbre_covar_69</th>\n",
              "      <th>timbre_covar_70</th>\n",
              "      <th>timbre_covar_71</th>\n",
              "      <th>timbre_covar_72</th>\n",
              "      <th>timbre_covar_73</th>\n",
              "      <th>timbre_covar_74</th>\n",
              "      <th>timbre_covar_75</th>\n",
              "      <th>timbre_covar_76</th>\n",
              "      <th>timbre_covar_77</th>\n",
              "      <th>timbre_covar_78</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2001</td>\n",
              "      <td>49.94357</td>\n",
              "      <td>21.47114</td>\n",
              "      <td>73.07750</td>\n",
              "      <td>8.74861</td>\n",
              "      <td>-17.40628</td>\n",
              "      <td>-13.09905</td>\n",
              "      <td>-25.01202</td>\n",
              "      <td>-12.23257</td>\n",
              "      <td>7.83089</td>\n",
              "      <td>...</td>\n",
              "      <td>13.01620</td>\n",
              "      <td>-54.40548</td>\n",
              "      <td>58.99367</td>\n",
              "      <td>15.37344</td>\n",
              "      <td>1.11144</td>\n",
              "      <td>-23.08793</td>\n",
              "      <td>68.40795</td>\n",
              "      <td>-1.82223</td>\n",
              "      <td>-27.46348</td>\n",
              "      <td>2.26327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>48.73215</td>\n",
              "      <td>18.42930</td>\n",
              "      <td>70.32679</td>\n",
              "      <td>12.94636</td>\n",
              "      <td>-10.32437</td>\n",
              "      <td>-24.83777</td>\n",
              "      <td>8.76630</td>\n",
              "      <td>-0.92019</td>\n",
              "      <td>18.76548</td>\n",
              "      <td>...</td>\n",
              "      <td>5.66812</td>\n",
              "      <td>-19.68073</td>\n",
              "      <td>33.04964</td>\n",
              "      <td>42.87836</td>\n",
              "      <td>-9.90378</td>\n",
              "      <td>-32.22788</td>\n",
              "      <td>70.49388</td>\n",
              "      <td>12.04941</td>\n",
              "      <td>58.43453</td>\n",
              "      <td>26.92061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2001</td>\n",
              "      <td>50.95714</td>\n",
              "      <td>31.85602</td>\n",
              "      <td>55.81851</td>\n",
              "      <td>13.41693</td>\n",
              "      <td>-6.57898</td>\n",
              "      <td>-18.54940</td>\n",
              "      <td>-3.27872</td>\n",
              "      <td>-2.35035</td>\n",
              "      <td>16.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>3.03800</td>\n",
              "      <td>26.05866</td>\n",
              "      <td>-50.92779</td>\n",
              "      <td>10.93792</td>\n",
              "      <td>-0.07568</td>\n",
              "      <td>43.20130</td>\n",
              "      <td>-115.00698</td>\n",
              "      <td>-0.05859</td>\n",
              "      <td>39.67068</td>\n",
              "      <td>-0.66345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001</td>\n",
              "      <td>48.24750</td>\n",
              "      <td>-1.89837</td>\n",
              "      <td>36.29772</td>\n",
              "      <td>2.58776</td>\n",
              "      <td>0.97170</td>\n",
              "      <td>-26.21683</td>\n",
              "      <td>5.05097</td>\n",
              "      <td>-10.34124</td>\n",
              "      <td>3.55005</td>\n",
              "      <td>...</td>\n",
              "      <td>34.57337</td>\n",
              "      <td>-171.70734</td>\n",
              "      <td>-16.96705</td>\n",
              "      <td>-46.67617</td>\n",
              "      <td>-12.51516</td>\n",
              "      <td>82.58061</td>\n",
              "      <td>-72.08993</td>\n",
              "      <td>9.90558</td>\n",
              "      <td>199.62971</td>\n",
              "      <td>18.85382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2001</td>\n",
              "      <td>50.97020</td>\n",
              "      <td>42.20998</td>\n",
              "      <td>67.09964</td>\n",
              "      <td>8.46791</td>\n",
              "      <td>-15.85279</td>\n",
              "      <td>-16.81409</td>\n",
              "      <td>-12.48207</td>\n",
              "      <td>-9.37636</td>\n",
              "      <td>12.63699</td>\n",
              "      <td>...</td>\n",
              "      <td>9.92661</td>\n",
              "      <td>-55.95724</td>\n",
              "      <td>64.92712</td>\n",
              "      <td>-17.72522</td>\n",
              "      <td>-1.49237</td>\n",
              "      <td>-7.50035</td>\n",
              "      <td>51.76631</td>\n",
              "      <td>7.88713</td>\n",
              "      <td>55.66926</td>\n",
              "      <td>28.74903</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 91 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5402f411-7e5e-4b50-bb46-1486cf4ba3ef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5402f411-7e5e-4b50-bb46-1486cf4ba3ef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5402f411-7e5e-4b50-bb46-1486cf4ba3ef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "colnames = ['target'] + ['timbre_avg_' + str(i) for i in range(1, 13)] + ['timbre_covar_' + str(i) for i in range(1, 79)]\n",
        "df = pd.read_csv('YearPredictionMSD.txt', header=None, names=colnames)\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqj7q70Ql5lb"
      },
      "source": [
        "Write a function to load the dataset, e.g.,\n",
        "`trainYears, trainFeat, testYears, testFeat = loadMusicData(fname, addBias)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HO0rnbz9STFd"
      },
      "outputs": [],
      "source": [
        "def loadMusicData(data, addBias=True):\n",
        "  train_df = data[:463714]\n",
        "  test_df = data[463714:]\n",
        "  train_y = train_df['target'].values\n",
        "  train_x = train_df.iloc[:,1:].values\n",
        "  test_y = test_df['target'].values\n",
        "  test_x = test_df.iloc[:,1:].values\n",
        "  if addBias:\n",
        "    train_x = np.hstack((train_x, np.ones((train_x.shape[0],1))))\n",
        "    test_x = np.hstack((test_x, np.ones((test_x.shape[0],1))))\n",
        "  return train_y, train_x, test_y, test_x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iz0sr2dbmDpu"
      },
      "source": [
        "Write a function `mse = musicMSE(pred, gt)` where the inputs are the predicted year and the “ground truth” year from the dataset. The function computes the mean squared error(MSE) by rounding pred before computing the MSE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eBi_cfQ4nGmY"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "def musicMSE(pred, gt):\n",
        "  pred = np.round(pred)\n",
        "  mse= mean_squared_error(pred, gt)\n",
        "  return mse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNpBvB08ojLl"
      },
      "source": [
        "Load the dataset and discuss its properties. \n",
        "1. What is the range of the variables? From 90 attributes, range of variables for timbre average is tighter than range of variables for timbre covariance. However, within each category itself, some attributes have wider range compared to others, in which we don't have further documentation to explain this event.\n",
        "2. How might you normalize them? Normalization can help to ensure that each variables contribute equally to the model. Since range of variables varies significantly accross 90 attributes, I will normalize the data using standardization technique (0 mean and unit std deviation for each attribute) where we can help to preserve importance of variables.\n",
        "3. What years are represented in the dataset? The dataset covers song released from 1922 to 2011 (90 years) with most common year of 2007.\n",
        "4. What will the test mean squared error (MSE) be if your classifier always outputs the most common year in the dataset? 190.08"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwHVPkNVoTmn",
        "outputId": "df3b1f88-37f1-4d5b-9476-6135fa71cc46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variable 1: range = 60\n",
            "Variable 2: range = 721\n",
            "Variable 3: range = 624\n",
            "Variable 4: range = 490\n",
            "Variable 5: range = 444\n",
            "Variable 6: range = 248\n",
            "Variable 7: range = 361\n",
            "Variable 8: range = 199\n",
            "Variable 9: range = 273\n",
            "Variable 10: range = 102\n",
            "Variable 11: range = 158\n",
            "Variable 12: range = 182\n",
            "Variable 13: range = 550\n",
            "Variable 14: range = 65727\n",
            "Variable 15: range = 36796\n",
            "Variable 16: range = 31832\n",
            "Variable 17: range = 19854\n",
            "Variable 18: range = 16826\n",
            "Variable 19: range = 11882\n",
            "Variable 20: range = 9564\n",
            "Variable 21: range = 9610\n",
            "Variable 22: range = 3707\n",
            "Variable 23: range = 6731\n",
            "Variable 24: range = 9808\n",
            "Variable 25: range = 4871\n",
            "Variable 26: range = 37870\n",
            "Variable 27: range = 26522\n",
            "Variable 28: range = 7735\n",
            "Variable 29: range = 6635\n",
            "Variable 30: range = 6669\n",
            "Variable 31: range = 6153\n",
            "Variable 32: range = 3471\n",
            "Variable 33: range = 4567\n",
            "Variable 34: range = 3921\n",
            "Variable 35: range = 2803\n",
            "Variable 36: range = 4208\n",
            "Variable 37: range = 22597\n",
            "Variable 38: range = 18155\n",
            "Variable 39: range = 15869\n",
            "Variable 40: range = 16243\n",
            "Variable 41: range = 8211\n",
            "Variable 42: range = 8068\n",
            "Variable 43: range = 6178\n",
            "Variable 44: range = 2904\n",
            "Variable 45: range = 1768\n",
            "Variable 46: range = 2529\n",
            "Variable 47: range = 23921\n",
            "Variable 48: range = 10960\n",
            "Variable 49: range = 12815\n",
            "Variable 50: range = 4412\n",
            "Variable 51: range = 3698\n",
            "Variable 52: range = 4207\n",
            "Variable 53: range = 5583\n",
            "Variable 54: range = 5100\n",
            "Variable 55: range = 2263\n",
            "Variable 56: range = 12109\n",
            "Variable 57: range = 17812\n",
            "Variable 58: range = 17732\n",
            "Variable 59: range = 9176\n",
            "Variable 60: range = 8190\n",
            "Variable 61: range = 3711\n",
            "Variable 62: range = 2370\n",
            "Variable 63: range = 1413\n",
            "Variable 64: range = 21394\n",
            "Variable 65: range = 10254\n",
            "Variable 66: range = 7344\n",
            "Variable 67: range = 3254\n",
            "Variable 68: range = 7345\n",
            "Variable 69: range = 7192\n",
            "Variable 70: range = 1720\n",
            "Variable 71: range = 11016\n",
            "Variable 72: range = 11695\n",
            "Variable 73: range = 10525\n",
            "Variable 74: range = 3453\n",
            "Variable 75: range = 2666\n",
            "Variable 76: range = 1459\n",
            "Variable 77: range = 19852\n",
            "Variable 78: range = 5449\n",
            "Variable 79: range = 13578\n",
            "Variable 80: range = 8490\n",
            "Variable 81: range = 1279\n",
            "Variable 82: range = 8872\n",
            "Variable 83: range = 5021\n",
            "Variable 84: range = 4832\n",
            "Variable 85: range = 602\n",
            "Variable 86: range = 6831\n",
            "Variable 87: range = 7154\n",
            "Variable 88: range = 699\n",
            "Variable 89: range = 14852\n",
            "Variable 90: range = 1059\n"
          ]
        }
      ],
      "source": [
        "# Range of variables\n",
        "var_ranges = np.ptp(df.iloc[:, 1:].values, axis=0)\n",
        "for i, var_range in enumerate(var_ranges):\n",
        "    print(\"Variable {}: range = {:.0f}\".format(i+1, var_range))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6xcZrqpiyO0F"
      },
      "outputs": [],
      "source": [
        "#Normalize data using standardization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "def loadMusicData2(data, addBias=True):\n",
        "  train_df = data[:463714]\n",
        "  test_df = data[463714:]\n",
        "  train_y = train_df['target'].values\n",
        "  train_x = train_df.iloc[:,1:].values\n",
        "  test_y = test_df['target'].values\n",
        "  test_x = test_df.iloc[:,1:].values\n",
        "  train_x= scaler.fit_transform(train_x)\n",
        "  test_x= scaler.fit_transform(test_x)\n",
        "\n",
        "  if addBias:\n",
        "    train_x = np.hstack((train_x, np.ones((train_x.shape[0],1))))\n",
        "    test_x = np.hstack((test_x, np.ones((test_x.shape[0],1))))\n",
        "  \n",
        "\n",
        "  return train_y, train_x, test_y, test_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J88tbEW8y56c",
        "outputId": "f678b92e-7503-4ba5-fabf-d71452cf7393"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min years presented:  1922\n",
            "Max years presented:  2011\n",
            "Median years presented:  2002.0\n",
            "Most common year: 2007\n"
          ]
        }
      ],
      "source": [
        "#Years represented\n",
        "print('Min years presented: ', np.min(df['target']))\n",
        "print('Max years presented: ', np.max(df['target']))\n",
        "print('Median years presented: ', np.median(df['target']))\n",
        "\n",
        "from statistics import mode\n",
        "print('Most common year:', mode(df['target']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XsuMY-B-6Rq8"
      },
      "outputs": [],
      "source": [
        "train_y, train_x, test_y, test_x = loadMusicData2(df, addBias=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgxWh8BG6E15",
        "outputId": "b24548a9-c06e-4862-c666-d0934dd80924"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "190.08239236117836"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#test MSE\n",
        "musicMSE(torch.full((test_y.shape[0],), 2007), test_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzi847OP89JV"
      },
      "source": [
        "##2. Classification\n",
        "This problem could have been posed as a classification problem by treating each year as a category. What would be the problems with this approach? Support your argument by analyzing a bar chart with the year as the x-axis and the number of examples for that year as the y-axis.\n",
        "\n",
        "As we can see from the chart, the distribution of train dataset is skewed to the left where majority of the data coming from the later years. If we treat this problem as a classification problem, the model will be biased and will be more likely to predict later years. Furthermore, classification means that the predicted data will be categorical values instead of continuous which can result in loss of information as repercussion. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "QByIY0eo3_uO",
        "outputId": "411c2e65-d3c6-4395-c7e3-a2a5bd48f8ca"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#plot year frequency from train dataset\n",
        "import matplotlib.pyplot as plt\n",
        "train_df = df[:463714]\n",
        "year_counts = train_df.iloc[:, 0].value_counts()\n",
        "plt.bar(year_counts.index, year_counts.values)\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiR5yP7wBxka"
      },
      "source": [
        "##3. Ridge regression\n",
        "\n",
        "* Implement stochastic gradient descent with mini-batches to minimize the loss and evaluate the train and test MSE.\n",
        "* Tune the learning rate and weight decay factor. \n",
        "* Show the train and test loss as a function of epochs, where the number of epochs should be chosen to ensure the train loss is minimized."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mini_batch_gradient_descent(X_train, y_train, X_test, y_test, batch_size=32, num_epochs=100, learning_rate=0.01, weight_decay_factor=0, loss_type='L2', weight_decay_form='none', momentum=False, momentum_factor=0.9):\n",
        "    num_features = X_train.shape[1]\n",
        "    num_batches = int(np.ceil(len(X_train) / batch_size))\n",
        "    weight = np.random.normal(size=num_features)\n",
        "    m = np.zeros_like(weight)\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "\n",
        "    def forward(X, w):\n",
        "        return np.dot(X, w)\n",
        "\n",
        "    def backward(X, error):\n",
        "        return np.dot(X.T, error)\n",
        "\n",
        "    def compute_gradient(X, y, y_pred, loss_type, w):\n",
        "      error = None\n",
        "      if loss_type == \"L2\":\n",
        "          error = 2*(y_pred - y)\n",
        "      elif loss_type == \"count\":\n",
        "          error = np.round(y_pred) - np.round(y)\n",
        "      elif loss_type == \"cross-entropy\":\n",
        "          error = y_pred - y\n",
        "      elif loss_type == 'L1':\n",
        "          error = np.sign(y_pred - y)\n",
        "      gradient = backward(X, error)\n",
        "      if weight_decay_form == 'L2':\n",
        "          gradient += weight_decay_factor * w\n",
        "      elif weight_decay_form == 'L1':\n",
        "          gradient += weight_decay_factor * np.sign(w)\n",
        "      return gradient, error\n",
        "\n",
        "    def compute_loss(y, y_pred, loss_type):\n",
        "        if loss_type == \"L2\":\n",
        "            return np.mean(np.square(y - y_pred))\n",
        "        elif loss_type == \"count\":\n",
        "            return np.mean(np.abs(np.round(y) - np.round(y_pred)))\n",
        "        elif loss_type == \"cross-entropy\":\n",
        "            y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)  # clip predictions\n",
        "            return -np.mean(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n",
        "        elif loss_type == 'L1':\n",
        "            return np.mean(np.abs(y - y_pred))\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Shuffle the data\n",
        "        perm = np.random.permutation(len(X_train))\n",
        "        X_train = X_train[perm]\n",
        "        y_train = y_train[perm]\n",
        "\n",
        "        # Mini-batch gradient descent\n",
        "        for i in range(num_batches):\n",
        "            start_idx = i * batch_size\n",
        "            end_idx = (i + 1) * batch_size\n",
        "            X_batch = X_train[start_idx:end_idx]\n",
        "            y_batch = y_train[start_idx:end_idx]\n",
        "\n",
        "            y_pred = forward(X_batch, weight)\n",
        "            gradient, error = compute_gradient(X_batch, y_batch, y_pred, loss_type, weight)\n",
        "\n",
        "            if momentum:\n",
        "              m = momentum_factor * m + (1 - momentum_factor) * gradient\n",
        "              weight -= learning_rate * m\n",
        "            else:\n",
        "                weight -= learning_rate * gradient.reshape(weight.shape)\n",
        "\n",
        "        # Compute train and test losses\n",
        "        y_train_pred = forward(X_train, weight)\n",
        "        train_loss = compute_loss(y_train, y_train_pred, loss_type)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        y_test_pred = forward(X_test, weight)\n",
        "        test_loss = compute_loss(y_test, y_test_pred, loss_type)\n",
        "        test_losses.append(test_loss)\n",
        "\n",
        "        print(\"Epoch:\", epoch+1, \"/100, Train loss:\", train_loss, \"Test loss:\", test_loss)\n",
        "\n",
        "    return weight, train_losses, test_losses\n"
      ],
      "metadata": {
        "id": "f7u12GIuw_jz"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter tuning\n",
        "* Learning rate= 0.0001\n",
        "* Weight decay factor= 0.000001\n",
        "* Batch size=16\n",
        "* Number epochs=100\n",
        "* Loss type= L2\n",
        "* Weight decay form= None\n",
        "* No momentum\n",
        "\n"
      ],
      "metadata": {
        "id": "r27YeMIDlVMX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "lHLX_tNcbLWr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa8d463a-946c-4756-dbde-5e45f5d0ccee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 /100, Train loss: 623993.0695500606 Test loss: 624164.5710245135\n",
            "Epoch: 2 /100, Train loss: 97708.08362873534 Test loss: 97775.06329043131\n",
            "Epoch: 3 /100, Train loss: 15365.406060394334 Test loss: 15391.306791625531\n",
            "Epoch: 4 /100, Train loss: 2482.5005082361145 Test loss: 2492.281408399886\n",
            "Epoch: 5 /100, Train loss: 466.351398897583 Test loss: 469.5150326235186\n",
            "Epoch: 6 /100, Train loss: 150.7162780758702 Test loss: 151.41107285919938\n",
            "Epoch: 7 /100, Train loss: 101.13699128225292 Test loss: 100.8017505141699\n",
            "Epoch: 8 /100, Train loss: 93.24964212825708 Test loss: 92.57233653737065\n",
            "Epoch: 9 /100, Train loss: 91.91672099772319 Test loss: 91.12752286507866\n",
            "Epoch: 10 /100, Train loss: 91.62505329544001 Test loss: 90.80538725664017\n",
            "Epoch: 11 /100, Train loss: 91.51752221914884 Test loss: 90.62941069466477\n",
            "Epoch: 12 /100, Train loss: 91.45547954563614 Test loss: 90.58494094731124\n",
            "Epoch: 13 /100, Train loss: 91.41180764413103 Test loss: 90.57193704832281\n",
            "Epoch: 14 /100, Train loss: 91.38010654236724 Test loss: 90.5222731311013\n",
            "Epoch: 15 /100, Train loss: 91.35697499437302 Test loss: 90.52360656972118\n",
            "Epoch: 16 /100, Train loss: 91.33649106762648 Test loss: 90.51133552348193\n",
            "Epoch: 17 /100, Train loss: 91.32116293512472 Test loss: 90.48454253941844\n",
            "Epoch: 18 /100, Train loss: 91.30996552595836 Test loss: 90.48935844121151\n",
            "Epoch: 19 /100, Train loss: 91.30001506064193 Test loss: 90.4874154062912\n",
            "Epoch: 20 /100, Train loss: 91.29300932420779 Test loss: 90.48506771830198\n",
            "Epoch: 21 /100, Train loss: 91.28800158843819 Test loss: 90.48876996599147\n",
            "Epoch: 22 /100, Train loss: 91.28033357611687 Test loss: 90.48015191507804\n",
            "Epoch: 23 /100, Train loss: 91.27589698446221 Test loss: 90.48473585364587\n",
            "Epoch: 24 /100, Train loss: 91.27677192623227 Test loss: 90.45788594026389\n",
            "Epoch: 25 /100, Train loss: 91.27105593159091 Test loss: 90.48817047774635\n",
            "Epoch: 26 /100, Train loss: 91.26861623608376 Test loss: 90.49168804977346\n",
            "Epoch: 27 /100, Train loss: 91.27189718233012 Test loss: 90.52514841090131\n",
            "Epoch: 28 /100, Train loss: 91.26624031026114 Test loss: 90.46914849959505\n",
            "Epoch: 29 /100, Train loss: 91.26407859900894 Test loss: 90.47356962839281\n",
            "Epoch: 30 /100, Train loss: 91.26550300005749 Test loss: 90.51069688378121\n",
            "Epoch: 31 /100, Train loss: 91.26297688092035 Test loss: 90.46404159228197\n",
            "Epoch: 32 /100, Train loss: 91.2623724337224 Test loss: 90.49083289465096\n",
            "Epoch: 33 /100, Train loss: 91.26312393711447 Test loss: 90.45475405263738\n",
            "Epoch: 34 /100, Train loss: 91.25984728112441 Test loss: 90.50145650794916\n",
            "Epoch: 35 /100, Train loss: 91.26657718884786 Test loss: 90.44263652905485\n",
            "Epoch: 36 /100, Train loss: 91.26067310609989 Test loss: 90.4698285272137\n",
            "Epoch: 37 /100, Train loss: 91.26370158145383 Test loss: 90.5072096404695\n",
            "Epoch: 38 /100, Train loss: 91.25889343063528 Test loss: 90.48103743866952\n",
            "Epoch: 39 /100, Train loss: 91.25892239302588 Test loss: 90.48083408773522\n",
            "Epoch: 40 /100, Train loss: 91.26549700969207 Test loss: 90.55998866801092\n",
            "Epoch: 41 /100, Train loss: 91.2587683119527 Test loss: 90.47914874223261\n",
            "Epoch: 42 /100, Train loss: 91.26158500548202 Test loss: 90.50207388407848\n",
            "Epoch: 43 /100, Train loss: 91.25871963674845 Test loss: 90.50203095222071\n",
            "Epoch: 44 /100, Train loss: 91.25864093074301 Test loss: 90.50333315058042\n",
            "Epoch: 45 /100, Train loss: 91.25786231284597 Test loss: 90.49275941549107\n",
            "Epoch: 46 /100, Train loss: 91.25843704468834 Test loss: 90.49457218400892\n",
            "Epoch: 47 /100, Train loss: 91.2586135322484 Test loss: 90.47749841986233\n",
            "Epoch: 48 /100, Train loss: 91.25897634640975 Test loss: 90.48496370739747\n",
            "Epoch: 49 /100, Train loss: 91.25855777279236 Test loss: 90.48975204500796\n",
            "Epoch: 50 /100, Train loss: 91.25931652427798 Test loss: 90.50145455691778\n",
            "Epoch: 51 /100, Train loss: 91.25954846734398 Test loss: 90.49118254965572\n",
            "Epoch: 52 /100, Train loss: 91.26065935344143 Test loss: 90.47479953401603\n",
            "Epoch: 53 /100, Train loss: 91.25816658278048 Test loss: 90.48284239726797\n",
            "Epoch: 54 /100, Train loss: 91.25788375966127 Test loss: 90.51113305281667\n",
            "Epoch: 55 /100, Train loss: 91.2582347585306 Test loss: 90.47489737766581\n",
            "Epoch: 56 /100, Train loss: 91.26026222700222 Test loss: 90.48679976131083\n",
            "Epoch: 57 /100, Train loss: 91.2587643679772 Test loss: 90.49447683494195\n",
            "Epoch: 58 /100, Train loss: 91.25936918007775 Test loss: 90.47631039271178\n",
            "Epoch: 59 /100, Train loss: 91.25804873835307 Test loss: 90.51306118318014\n",
            "Epoch: 60 /100, Train loss: 91.2594545060345 Test loss: 90.45959801637372\n",
            "Epoch: 61 /100, Train loss: 91.2584159808608 Test loss: 90.49565863942532\n",
            "Epoch: 62 /100, Train loss: 91.26267510996914 Test loss: 90.47357107281574\n",
            "Epoch: 63 /100, Train loss: 91.25826526347421 Test loss: 90.47242835693017\n",
            "Epoch: 64 /100, Train loss: 91.25891235360916 Test loss: 90.4990261423209\n",
            "Epoch: 65 /100, Train loss: 91.25773014529128 Test loss: 90.49929715853119\n",
            "Epoch: 66 /100, Train loss: 91.25830163783138 Test loss: 90.50616527388925\n",
            "Epoch: 67 /100, Train loss: 91.25912633759204 Test loss: 90.49555323481714\n",
            "Epoch: 68 /100, Train loss: 91.26134861485866 Test loss: 90.52126444423854\n",
            "Epoch: 69 /100, Train loss: 91.25841476982937 Test loss: 90.5027102271548\n",
            "Epoch: 70 /100, Train loss: 91.25844905219283 Test loss: 90.49013447856997\n",
            "Epoch: 71 /100, Train loss: 91.25791184066064 Test loss: 90.48932391228256\n",
            "Epoch: 72 /100, Train loss: 91.26027000790766 Test loss: 90.4636047847537\n",
            "Epoch: 73 /100, Train loss: 91.25954657812845 Test loss: 90.48725456402016\n",
            "Epoch: 74 /100, Train loss: 91.25810337416961 Test loss: 90.47701442154707\n",
            "Epoch: 75 /100, Train loss: 91.25915511088346 Test loss: 90.50618362716979\n",
            "Epoch: 76 /100, Train loss: 91.26051603302449 Test loss: 90.52540973105799\n",
            "Epoch: 77 /100, Train loss: 91.26124122080272 Test loss: 90.4734538166575\n",
            "Epoch: 78 /100, Train loss: 91.25886208723952 Test loss: 90.51901893165969\n",
            "Epoch: 79 /100, Train loss: 91.26001469917806 Test loss: 90.46533292407489\n",
            "Epoch: 80 /100, Train loss: 91.2585289897044 Test loss: 90.4998000275836\n",
            "Epoch: 81 /100, Train loss: 91.2630596709094 Test loss: 90.4560724547599\n",
            "Epoch: 82 /100, Train loss: 91.25775496398944 Test loss: 90.49291630957173\n",
            "Epoch: 83 /100, Train loss: 91.25937539602418 Test loss: 90.49282280807441\n",
            "Epoch: 84 /100, Train loss: 91.25823576115245 Test loss: 90.51415250603598\n",
            "Epoch: 85 /100, Train loss: 91.25922699828186 Test loss: 90.49949355002931\n",
            "Epoch: 86 /100, Train loss: 91.25922036879811 Test loss: 90.5097576580547\n",
            "Epoch: 87 /100, Train loss: 91.25880613358225 Test loss: 90.50955388299562\n",
            "Epoch: 88 /100, Train loss: 91.25808885281998 Test loss: 90.49148021912653\n",
            "Epoch: 89 /100, Train loss: 91.25822647783036 Test loss: 90.48476811970997\n",
            "Epoch: 90 /100, Train loss: 91.26103377710469 Test loss: 90.5114393264792\n",
            "Epoch: 91 /100, Train loss: 91.2591755301005 Test loss: 90.47917644784467\n",
            "Epoch: 92 /100, Train loss: 91.25988096956269 Test loss: 90.5033179333578\n",
            "Epoch: 93 /100, Train loss: 91.25923783019194 Test loss: 90.47262156589095\n",
            "Epoch: 94 /100, Train loss: 91.25943228109502 Test loss: 90.48393960022287\n",
            "Epoch: 95 /100, Train loss: 91.25793651542827 Test loss: 90.47323424319377\n",
            "Epoch: 96 /100, Train loss: 91.26095233162435 Test loss: 90.4654413007741\n",
            "Epoch: 97 /100, Train loss: 91.26182965470002 Test loss: 90.51474515367961\n",
            "Epoch: 98 /100, Train loss: 91.2602688659543 Test loss: 90.46537469811757\n",
            "Epoch: 99 /100, Train loss: 91.2601976624902 Test loss: 90.49269049118051\n",
            "Epoch: 100 /100, Train loss: 91.2605350284773 Test loss: 90.51601873576014\n"
          ]
        }
      ],
      "source": [
        "w_ridge, train_loss_ridge, test_loss_ridge = mini_batch_gradient_descent(train_x, train_y, test_x, test_y, batch_size=16, num_epochs=100, learning_rate=0.000001, weight_decay_factor=0.000001, loss_type='L2', weight_decay_form=None, momentum=False, momentum_factor=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7olCs7GbNW5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "26c821ec-eec4-4edb-8ff6-cd1287de5875"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "num_epochs=100\n",
        "plt.plot(range(num_epochs), train_loss_ridge,'r', label=\"Train loss\")\n",
        "plt.plot(range(num_epochs), test_loss_ridge, 'bo',label=\"Test loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9ap9a_o1OGE"
      },
      "source": [
        "Pseudoinverse"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_loss(X, y, weight, loss_type):\n",
        "    if loss_type == 'L2':\n",
        "        loss = np.mean((np.dot(X, weight) - y) ** 2)\n",
        "    elif loss_type == 'count':\n",
        "        loss = np.mean(np.abs(np.dot(X, weight) - y))\n",
        "    elif loss_type == 'cross-entropy':\n",
        "        exp_term = np.exp(np.dot(X, weight))\n",
        "        loss = np.mean(np.log(1 + exp_term) - y * np.dot(X, weight))\n",
        "    return loss\n",
        "\n",
        "def pseudoinverse(train_x, train_y, test_x, test_y, alpha=0, loss_type='L2'):\n",
        "    pseudoinv= np.dot(np.linalg.inv(train_x.T.dot(train_x) + alpha*np.eye(train_x.shape[1])), train_x.T)\n",
        "    weight= np.dot(pseudoinv, train_y)\n",
        "    train_y_predict= np.dot(train_x, weight)\n",
        "    test_y_predict= np.dot(test_x, weight)\n",
        "\n",
        "    train_loss= compute_loss(train_x, train_y, weight, loss_type=loss_type)\n",
        "    test_loss= compute_loss(test_x, test_y,weight, loss_type=loss_type)\n",
        "  \n",
        "    print(f'Train loss: {train_loss:.4f}, Test loss: {test_loss:.4f}')\n",
        "    \n",
        "    return weight, train_loss, test_loss"
      ],
      "metadata": {
        "id": "ohY45Ph3pYrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_inverse, train_loss_inverse, test_loss_inverse = pseudoinverse(train_x, train_y, test_x, test_y, alpha=0, loss_type='L2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUVECvJdDX7I",
        "outputId": "3e9ebb86-0f4f-4ef7-fcc7-08e797bc09ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 91.2564, Test loss: 90.4911\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Implement L1 weight decay"
      ],
      "metadata": {
        "id": "jL8oRaDeDY-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w_lasso, train_loss_lasso, test_loss_lasso = mini_batch_gradient_descent(train_x, train_y, test_x, test_y, batch_size=32, num_epochs=100, learning_rate=0.0001, weight_decay_factor=0.1, loss_type='L1', weight_decay_form='L1', momentum=False, momentum_factor=None)\n",
        "num_epochs=100\n",
        "plt.plot(range(num_epochs), train_loss_lasso,'r', label=\"Train loss\")\n",
        "plt.plot(range(num_epochs), test_loss_lasso, 'bo',label=\"Test loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "erfbyKAdDhYL",
        "outputId": "149f9e06-396f-4b9f-a83d-ed2551f466bf"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 /100, Train loss: 1950.9301810614334 Test loss: 1951.0400277219026\n",
            "Epoch: 2 /100, Train loss: 1904.703701061418 Test loss: 1904.813547721887\n",
            "Epoch: 3 /100, Train loss: 1858.4772210614192 Test loss: 1858.5870677218886\n",
            "Epoch: 4 /100, Train loss: 1812.2507410615742 Test loss: 1812.3605877220427\n",
            "Epoch: 5 /100, Train loss: 1766.0242610617274 Test loss: 1766.1341077221969\n",
            "Epoch: 6 /100, Train loss: 1719.79778106168 Test loss: 1719.9076277221498\n",
            "Epoch: 7 /100, Train loss: 1673.571301061423 Test loss: 1673.6811477218919\n",
            "Epoch: 8 /100, Train loss: 1627.344821061165 Test loss: 1627.4546677216342\n",
            "Epoch: 9 /100, Train loss: 1581.1183410609078 Test loss: 1581.2281877213763\n",
            "Epoch: 10 /100, Train loss: 1534.8918610606495 Test loss: 1535.0017077211187\n",
            "Epoch: 11 /100, Train loss: 1488.6653810603925 Test loss: 1488.775227720861\n",
            "Epoch: 12 /100, Train loss: 1442.438901060134 Test loss: 1442.548747720603\n",
            "Epoch: 13 /100, Train loss: 1396.2124210598763 Test loss: 1396.3222677203455\n",
            "Epoch: 14 /100, Train loss: 1349.9859410596187 Test loss: 1350.0957877200876\n",
            "Epoch: 15 /100, Train loss: 1303.7594610593605 Test loss: 1303.86930771983\n",
            "Epoch: 16 /100, Train loss: 1257.5329810591031 Test loss: 1257.6428277195719\n",
            "Epoch: 17 /100, Train loss: 1211.3065010588452 Test loss: 1211.4163477193142\n",
            "Epoch: 18 /100, Train loss: 1165.0800210585874 Test loss: 1165.1898677190566\n",
            "Epoch: 19 /100, Train loss: 1118.8535410583295 Test loss: 1118.9633877187987\n",
            "Epoch: 20 /100, Train loss: 1072.6270610580718 Test loss: 1072.7369077185408\n",
            "Epoch: 21 /100, Train loss: 1026.4005810578142 Test loss: 1026.5104277182832\n",
            "Epoch: 22 /100, Train loss: 980.1741010575564 Test loss: 980.2839477180255\n",
            "Epoch: 23 /100, Train loss: 933.9476210587399 Test loss: 934.0574677192088\n",
            "Epoch: 24 /100, Train loss: 887.7211410601294 Test loss: 887.8309877205985\n",
            "Epoch: 25 /100, Train loss: 841.4946610615192 Test loss: 841.604507721988\n",
            "Epoch: 26 /100, Train loss: 795.2681810629088 Test loss: 795.3780277233777\n",
            "Epoch: 27 /100, Train loss: 749.0417010642984 Test loss: 749.1515477247674\n",
            "Epoch: 28 /100, Train loss: 702.8152210656883 Test loss: 702.9250677261571\n",
            "Epoch: 29 /100, Train loss: 656.5887410670776 Test loss: 656.6985877275467\n",
            "Epoch: 30 /100, Train loss: 610.3622610684673 Test loss: 610.4721077289363\n",
            "Epoch: 31 /100, Train loss: 564.1357810698572 Test loss: 564.245627730326\n",
            "Epoch: 32 /100, Train loss: 517.9093010712469 Test loss: 518.0191477317156\n",
            "Epoch: 33 /100, Train loss: 471.68282107263644 Test loss: 471.7926677331053\n",
            "Epoch: 34 /100, Train loss: 425.45634107402606 Test loss: 425.56618773449503\n",
            "Epoch: 35 /100, Train loss: 379.22986107541567 Test loss: 379.33970773588476\n",
            "Epoch: 36 /100, Train loss: 333.00338107680534 Test loss: 333.11322773727437\n",
            "Epoch: 37 /100, Train loss: 286.77690107819507 Test loss: 286.8867477386641\n",
            "Epoch: 38 /100, Train loss: 240.5504210795848 Test loss: 240.66026774005377\n",
            "Epoch: 39 /100, Train loss: 194.32394108097446 Test loss: 194.43378774144344\n",
            "Epoch: 40 /100, Train loss: 148.0974610823641 Test loss: 148.20730774283308\n",
            "Epoch: 41 /100, Train loss: 101.87098108375379 Test loss: 101.98082774422275\n",
            "Epoch: 42 /100, Train loss: 55.689568831860626 Test loss: 55.79665463855028\n",
            "Epoch: 43 /100, Train loss: 14.625894222278342 Test loss: 14.664893120685463\n",
            "Epoch: 44 /100, Train loss: 6.585255904971756 Test loss: 6.593643633173447\n",
            "Epoch: 45 /100, Train loss: 6.53019469741385 Test loss: 6.541547468822418\n",
            "Epoch: 46 /100, Train loss: 6.51998880314693 Test loss: 6.533773745164131\n",
            "Epoch: 47 /100, Train loss: 6.5179766348302275 Test loss: 6.531660995207973\n",
            "Epoch: 48 /100, Train loss: 6.516289398550285 Test loss: 6.529627698193138\n",
            "Epoch: 49 /100, Train loss: 6.516034112312831 Test loss: 6.528229654915963\n",
            "Epoch: 50 /100, Train loss: 6.5169222878549595 Test loss: 6.530179371959833\n",
            "Epoch: 51 /100, Train loss: 6.5167397754086664 Test loss: 6.532360149341302\n",
            "Epoch: 52 /100, Train loss: 6.515583217833238 Test loss: 6.52824009033953\n",
            "Epoch: 53 /100, Train loss: 6.516737289020132 Test loss: 6.529083546468343\n",
            "Epoch: 54 /100, Train loss: 6.51557782861233 Test loss: 6.530821123467077\n",
            "Epoch: 55 /100, Train loss: 6.51558365868928 Test loss: 6.528507188299907\n",
            "Epoch: 56 /100, Train loss: 6.516186583787125 Test loss: 6.5303021729209245\n",
            "Epoch: 57 /100, Train loss: 6.5161288827144865 Test loss: 6.5316825572242285\n",
            "Epoch: 58 /100, Train loss: 6.517127980367098 Test loss: 6.530026554482017\n",
            "Epoch: 59 /100, Train loss: 6.515313602749752 Test loss: 6.529911685860553\n",
            "Epoch: 60 /100, Train loss: 6.516837294070451 Test loss: 6.533446064083174\n",
            "Epoch: 61 /100, Train loss: 6.516215905329635 Test loss: 6.530066959998989\n",
            "Epoch: 62 /100, Train loss: 6.516208067275089 Test loss: 6.5276071938000895\n",
            "Epoch: 63 /100, Train loss: 6.517126356709529 Test loss: 6.530336374882742\n",
            "Epoch: 64 /100, Train loss: 6.5158866044125565 Test loss: 6.530149772038286\n",
            "Epoch: 65 /100, Train loss: 6.516349630288369 Test loss: 6.525553866140266\n",
            "Epoch: 66 /100, Train loss: 6.515199412474455 Test loss: 6.528297132480572\n",
            "Epoch: 67 /100, Train loss: 6.516175294049129 Test loss: 6.527646547568924\n",
            "Epoch: 68 /100, Train loss: 6.515572933255709 Test loss: 6.529951316087097\n",
            "Epoch: 69 /100, Train loss: 6.515358867468304 Test loss: 6.530340023380803\n",
            "Epoch: 70 /100, Train loss: 6.515868631722628 Test loss: 6.5286095198702\n",
            "Epoch: 71 /100, Train loss: 6.515450697137879 Test loss: 6.528393097690255\n",
            "Epoch: 72 /100, Train loss: 6.515131789577384 Test loss: 6.530822886648729\n",
            "Epoch: 73 /100, Train loss: 6.51649227781784 Test loss: 6.531335460930988\n",
            "Epoch: 74 /100, Train loss: 6.516836845928441 Test loss: 6.528447147647712\n",
            "Epoch: 75 /100, Train loss: 6.516536885238397 Test loss: 6.528872912602708\n",
            "Epoch: 76 /100, Train loss: 6.515864996222254 Test loss: 6.527718042259983\n",
            "Epoch: 77 /100, Train loss: 6.516096636750008 Test loss: 6.529182484655822\n",
            "Epoch: 78 /100, Train loss: 6.515984065186161 Test loss: 6.530898841625088\n",
            "Epoch: 79 /100, Train loss: 6.516040255247726 Test loss: 6.531970925372026\n",
            "Epoch: 80 /100, Train loss: 6.516363740175475 Test loss: 6.5268566612798455\n",
            "Epoch: 81 /100, Train loss: 6.516121941351959 Test loss: 6.532996852320499\n",
            "Epoch: 82 /100, Train loss: 6.515295233477765 Test loss: 6.5288823389133475\n",
            "Epoch: 83 /100, Train loss: 6.51602285359191 Test loss: 6.529995479308426\n",
            "Epoch: 84 /100, Train loss: 6.515386015892401 Test loss: 6.527022723891145\n",
            "Epoch: 85 /100, Train loss: 6.514691504482082 Test loss: 6.529307762747398\n",
            "Epoch: 86 /100, Train loss: 6.517270851971052 Test loss: 6.533525064863008\n",
            "Epoch: 87 /100, Train loss: 6.515481517071464 Test loss: 6.5286247545365965\n",
            "Epoch: 88 /100, Train loss: 6.5153798598397605 Test loss: 6.528731395545174\n",
            "Epoch: 89 /100, Train loss: 6.517310686960089 Test loss: 6.529898014197973\n",
            "Epoch: 90 /100, Train loss: 6.515323283531018 Test loss: 6.52736317113097\n",
            "Epoch: 91 /100, Train loss: 6.515177343160028 Test loss: 6.52729943180442\n",
            "Epoch: 92 /100, Train loss: 6.515508493387368 Test loss: 6.526898834266126\n",
            "Epoch: 93 /100, Train loss: 6.5160789574650035 Test loss: 6.527319824891978\n",
            "Epoch: 94 /100, Train loss: 6.515202222768233 Test loss: 6.530334135593712\n",
            "Epoch: 95 /100, Train loss: 6.515245541690386 Test loss: 6.530768321052215\n",
            "Epoch: 96 /100, Train loss: 6.517258901319921 Test loss: 6.5327983702855486\n",
            "Epoch: 97 /100, Train loss: 6.516942488064987 Test loss: 6.53196632338511\n",
            "Epoch: 98 /100, Train loss: 6.516447314245719 Test loss: 6.526203936983125\n",
            "Epoch: 99 /100, Train loss: 6.515890205610809 Test loss: 6.527740448462714\n",
            "Epoch: 100 /100, Train loss: 6.515958870755062 Test loss: 6.532470440615759\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. Count Regression\n",
        "\n",
        "$$y_{pred} = e^{w^T X}$$\n",
        "$$L(y, y_{pred}) = e^{-y_{pred}} y_{pred}^y / y!$$\n",
        "$$L(w) = -\\sum_{i=1}^{n}(y_i log(y_{pred,i}) - y_{pred,i})$$\n",
        "$$ w_{t+1} = w_t - \\eta \\nabla J(w_t) $$"
      ],
      "metadata": {
        "id": "nCdeXttIDv23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_regression(X_train, y_train, X_test, y_test, batch_size=16, num_epochs=100, learning_rate=0.01, weight_decay_factor=0, loss_type='count', weight_decay_form='none', momentum=False, momentum_factor=0.9):\n",
        "    num_features = X_train.shape[1]\n",
        "    num_batches = int(np.ceil(len(X_train) / batch_size))\n",
        "    weight = np.random.normal(size=num_features)\n",
        "    m = 0\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "\n",
        "    def forward(X, w):\n",
        "      # Clip X * w to avoid overflow in the exponential function\n",
        "      Xw = np.clip(np.dot(X, w), -100, None)\n",
        "      # Apply the exponential function and replace any resulting inf or nan values\n",
        "      y_pred = np.where(np.isinf(np.exp(Xw)), 1e10, np.exp(np.clip(Xw, -500, 500)))\n",
        "      return y_pred\n",
        "\n",
        "    def backward(X, error):\n",
        "        return np.dot(X.T, error)\n",
        "\n",
        "    def compute_gradient(X, y, y_pred, loss_type, w):\n",
        "      error = None\n",
        "      if loss_type == \"L2\":\n",
        "          error = 2*(y_pred - y)\n",
        "      elif loss_type == \"count\":\n",
        "          # Clip y_pred to avoid overflow\n",
        "          y_pred_clipped = np.clip(y_pred, -100, None)\n",
        "          error = np.exp(-y_pred_clipped) * (y_pred - y)\n",
        "      elif loss_type == \"cross-entropy\":\n",
        "          error = y_pred - y\n",
        "\n",
        "      gradient = backward(X, error)\n",
        "      if weight_decay_form == 'L2':\n",
        "          gradient += weight_decay_factor * w\n",
        "      elif weight_decay_form == 'L1':\n",
        "          gradient += weight_decay_factor * np.sign(w)\n",
        "\n",
        "      return gradient, error\n",
        "\n",
        "\n",
        "    def compute_loss(y, y_pred, loss_type):\n",
        "      if loss_type == \"L2\":\n",
        "          return np.mean(np.square(y - y_pred))\n",
        "      elif loss_type == \"count\":\n",
        "          # Clip y_pred to avoid overflow\n",
        "          y_pred_clipped = np.clip(y_pred, -100, None)\n",
        "          return np.mean(np.exp(-y_pred_clipped) * np.square(y - y_pred))\n",
        "      elif loss_type == \"cross-entropy\":\n",
        "          y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)  # clip predictions\n",
        "          return -np.mean(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n",
        "      elif loss_type == 'L1':\n",
        "          return np.mean(np.abs(y - y_pred))\n",
        "      else:\n",
        "          raise ValueError(\"Invalid loss type: {}\".format(loss_type))\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Shuffle the data\n",
        "        perm = np.random.permutation(len(X_train))\n",
        "        X_train = X_train[perm]\n",
        "        y_train = y_train[perm]\n",
        "\n",
        "        # Mini-batch gradient descent\n",
        "        for i in range(num_batches):\n",
        "            start_idx = i * batch_size\n",
        "            end_idx = (i + 1) * batch_size\n",
        "            X_batch = X_train[start_idx:end_idx]\n",
        "            y_batch = y_train[start_idx:end_idx]\n",
        "\n",
        "            y_pred = forward(X_batch, weight)\n",
        "            gradient, error = compute_gradient(X_batch, y_batch, y_pred, loss_type, weight)\n",
        "\n",
        "            if momentum:\n",
        "                m = momentum_factor * m + (1 - momentum_factor) * gradient\n",
        "                weight -= learning_rate * m\n",
        "            else:\n",
        "                weight -= learning_rate * gradient\n",
        "\n",
        "        # Compute train and test losses\n",
        "        y_train_pred = forward(X_train, weight)\n",
        "        train_loss = compute_loss(y_train, y_train_pred, loss_type)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        y_test_pred = forward(X_test, weight)\n",
        "        test_loss = compute_loss(y_test, y_test_pred, loss_type)\n",
        "        test_losses.append(test_loss)\n",
        "\n",
        "        print(\"Epoch:\", epoch+1, \"/100, Train loss:\", train_loss, \"Test loss:\", test_loss)\n",
        "\n",
        "        # Check if the test loss has stopped decreasing\n",
        "        if len(test_losses) >= 2 and test_losses[-1] >= test_losses[-2]:\n",
        "            print(\"Test loss has stopped decreasing. Stopping training.\")\n",
        "            break\n",
        "\n",
        "    return weight, train_losses, test_losses"
      ],
      "metadata": {
        "id": "cNIIYX9ZDrWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w, train_loss, test_loss= count_regression(train_x, train_y, test_x, test_y, batch_size=16, num_epochs=100, learning_rate=0.0001, weight_decay_factor=0.0001, loss_type='L2', weight_decay_form='L1', momentum=False, momentum_factor=0.9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxuLKLGkG1m3",
        "outputId": "950f2c77-a04a-4207-edb6-30cbe638054c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-83-4fd2562a219d>:13: RuntimeWarning: overflow encountered in exp\n",
            "  y_pred = np.where(np.isinf(np.exp(Xw)), 1e10, np.exp(np.clip(Xw, -500, 500)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 /100, Train loss: 1.380160495777983e+16 Test loss: 1.5494561018500892e+16\n",
            "Epoch: 2 /100, Train loss: 3993666.588416567 Test loss: 1936820130274826.5\n",
            "Epoch: 3 /100, Train loss: 3993666.588416567 Test loss: 1936820130274826.5\n",
            "Test loss has stopped decreasing. Stopping training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=100\n",
        "plt.plot(range(num_epochs), train_loss,'r', label=\"Train loss\")\n",
        "plt.plot(range(num_epochs), test_loss, 'bo',label=\"Test loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "zs36ofwaG9q_",
        "outputId": "609e484b-40f7-43ca-aa88-48eddac43a3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6. Model comparison\n"
      ],
      "metadata": {
        "id": "m0zHKAuX2wv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fig, ax = plt.subplots(figsize=(8, 6))\n",
        "plt.hist(w_ridge, alpha=0.5, label='Ridge')\n",
        "plt.xlabel('Weight Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Weights - Ridge')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "iYbX4Db7jqkq",
        "outputId": "08e6653e-b37a-4194-8deb-390417fb2dd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(w_lasso, alpha=0.5, label='Lasso')\n",
        "plt.xlabel('Weight Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Weights - Lasso')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "kyqJJoVMEXKx",
        "outputId": "9970c72a-9a12-4080-9952-9b8bb4235d56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Ridge and Lasso regression, the weight is quite similar. It means that the penalty term applied is not really significant to the model.\n",
        "\n",
        "Lasso regression gives significantly lower loss. It's important to note that Lasso is better at handling multicollinearity by performing feature selection and shrinking the cofficient towards zero. This might indicates our data has high multicollinearity which resulting in Lasso performs better than Ridge.  However, since the weights are similar, it means that both Ridge and Lasso are able to capture relationships between the attributes and target varible."
      ],
      "metadata": {
        "id": "h8iRKY2fo7gS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HUi6LwWvqyY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 5 - Softmax Properties\n",
        "\n",
        "\n",
        "###1. Show that the softmax function is invariant to constant offsets to its input\n",
        "\n",
        "\\begin{align*}\n",
        "softmax(a+c1) &= \\frac{exp(a+c1)}{\\sum_{j=1}^{n}exp(a_j+c)} \\\\\n",
        "&= \\frac{exp(a)exp(c1)}{\\sum_{j=1}^{n}exp(a_j)exp(c)}\\\\\n",
        "&= \\frac{exp(a)}{\\sum_{j=1}^{n}exp(a_j)} \\times \\frac{exp(c1)}{\\sum_{j=1}^{n}exp(c)}{}\\\\\n",
        "&= softmax(a) \\times \\frac{exp(c1)}{n \\times exp(c)}{}\\\\\n",
        "&= softmax(a) \\times \\frac{exp(c1-c)}{n}\n",
        "\\end{align*}\n",
        "\n",
        "Since $\\frac{exp(c1-c)}{n}$ is a constant, it doesn't depend on $a$ and it's proven that softmax function is invariant to constant offset to its input.\n"
      ],
      "metadata": {
        "id": "Ri2DQfSOEA6H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.  Why is the observation that the softmax function is invariant to constant offsets to its input important when implementing it in a neural network?\n",
        "\n",
        "It's important that softmax function is invariant to constant offset to its input because it allows the model to be more robust to changes in input data. Adding or substracting a constant value from input data doesn't change the output of sofmax function and making the network to generalize better to new data that can improve reliability and accuracy."
      ],
      "metadata": {
        "id": "Pl2YQkyDNU7m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d7XFmHfPP_t3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OOZDHd3f5jKC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}