{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anastasiarenata1/deeplearning/blob/main/LNN_with_Numpy_and_Softmax_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRQriJO6Rw4D"
      },
      "source": [
        "# Problem 4 - Regression\n",
        "\n",
        "Classification data from 2011 Million Song Challenge dataset to predict music year\n",
        "\n",
        "* Explore three shallow (linear) neural network models with different activation functions for this task.\n",
        "* Evaluate the model by rounding the output of your linear neural network and compute the mean squared error\n",
        "\n",
        "\n",
        "###1. Load and explore the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEErmxZU2EDU",
        "outputId": "fdc247a9-b02b-494a-d7d6-980743c57036"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-02 19:54:54--  https://archive.ics.uci.edu/ml/machine-learning-databases/00203/YearPredictionMSD.txt.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 211011981 (201M) [application/x-httpd-php]\n",
            "Saving to: ‘YearPredictionMSD.txt.zip.1’\n",
            "\n",
            "YearPredictionMSD.t 100%[===================>] 201.24M  44.0MB/s    in 5.2s    \n",
            "\n",
            "2023-03-02 19:54:59 (38.7 MB/s) - ‘YearPredictionMSD.txt.zip.1’ saved [211011981/211011981]\n",
            "\n",
            "Archive:  YearPredictionMSD.txt.zip\n",
            "replace YearPredictionMSD.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: YearPredictionMSD.txt   \n"
          ]
        }
      ],
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00203/YearPredictionMSD.txt.zip\n",
        "!unzip YearPredictionMSD.txt.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYGlyolcU0ai"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "BbPalayaR_Kz",
        "outputId": "b55e9215-73ea-4024-811c-ac99aa8976f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   target  timbre_avg_1  timbre_avg_2  timbre_avg_3  timbre_avg_4  \\\n",
              "0    2001      49.94357      21.47114      73.07750       8.74861   \n",
              "1    2001      48.73215      18.42930      70.32679      12.94636   \n",
              "2    2001      50.95714      31.85602      55.81851      13.41693   \n",
              "3    2001      48.24750      -1.89837      36.29772       2.58776   \n",
              "4    2001      50.97020      42.20998      67.09964       8.46791   \n",
              "\n",
              "   timbre_avg_5  timbre_avg_6  timbre_avg_7  timbre_avg_8  timbre_avg_9  ...  \\\n",
              "0     -17.40628     -13.09905     -25.01202     -12.23257       7.83089  ...   \n",
              "1     -10.32437     -24.83777       8.76630      -0.92019      18.76548  ...   \n",
              "2      -6.57898     -18.54940      -3.27872      -2.35035      16.07017  ...   \n",
              "3       0.97170     -26.21683       5.05097     -10.34124       3.55005  ...   \n",
              "4     -15.85279     -16.81409     -12.48207      -9.37636      12.63699  ...   \n",
              "\n",
              "   timbre_covar_69  timbre_covar_70  timbre_covar_71  timbre_covar_72  \\\n",
              "0         13.01620        -54.40548         58.99367         15.37344   \n",
              "1          5.66812        -19.68073         33.04964         42.87836   \n",
              "2          3.03800         26.05866        -50.92779         10.93792   \n",
              "3         34.57337       -171.70734        -16.96705        -46.67617   \n",
              "4          9.92661        -55.95724         64.92712        -17.72522   \n",
              "\n",
              "   timbre_covar_73  timbre_covar_74  timbre_covar_75  timbre_covar_76  \\\n",
              "0          1.11144        -23.08793         68.40795         -1.82223   \n",
              "1         -9.90378        -32.22788         70.49388         12.04941   \n",
              "2         -0.07568         43.20130       -115.00698         -0.05859   \n",
              "3        -12.51516         82.58061        -72.08993          9.90558   \n",
              "4         -1.49237         -7.50035         51.76631          7.88713   \n",
              "\n",
              "   timbre_covar_77  timbre_covar_78  \n",
              "0        -27.46348          2.26327  \n",
              "1         58.43453         26.92061  \n",
              "2         39.67068         -0.66345  \n",
              "3        199.62971         18.85382  \n",
              "4         55.66926         28.74903  \n",
              "\n",
              "[5 rows x 91 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4275d364-aace-4267-9856-21f37b522bd8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>timbre_avg_1</th>\n",
              "      <th>timbre_avg_2</th>\n",
              "      <th>timbre_avg_3</th>\n",
              "      <th>timbre_avg_4</th>\n",
              "      <th>timbre_avg_5</th>\n",
              "      <th>timbre_avg_6</th>\n",
              "      <th>timbre_avg_7</th>\n",
              "      <th>timbre_avg_8</th>\n",
              "      <th>timbre_avg_9</th>\n",
              "      <th>...</th>\n",
              "      <th>timbre_covar_69</th>\n",
              "      <th>timbre_covar_70</th>\n",
              "      <th>timbre_covar_71</th>\n",
              "      <th>timbre_covar_72</th>\n",
              "      <th>timbre_covar_73</th>\n",
              "      <th>timbre_covar_74</th>\n",
              "      <th>timbre_covar_75</th>\n",
              "      <th>timbre_covar_76</th>\n",
              "      <th>timbre_covar_77</th>\n",
              "      <th>timbre_covar_78</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2001</td>\n",
              "      <td>49.94357</td>\n",
              "      <td>21.47114</td>\n",
              "      <td>73.07750</td>\n",
              "      <td>8.74861</td>\n",
              "      <td>-17.40628</td>\n",
              "      <td>-13.09905</td>\n",
              "      <td>-25.01202</td>\n",
              "      <td>-12.23257</td>\n",
              "      <td>7.83089</td>\n",
              "      <td>...</td>\n",
              "      <td>13.01620</td>\n",
              "      <td>-54.40548</td>\n",
              "      <td>58.99367</td>\n",
              "      <td>15.37344</td>\n",
              "      <td>1.11144</td>\n",
              "      <td>-23.08793</td>\n",
              "      <td>68.40795</td>\n",
              "      <td>-1.82223</td>\n",
              "      <td>-27.46348</td>\n",
              "      <td>2.26327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>48.73215</td>\n",
              "      <td>18.42930</td>\n",
              "      <td>70.32679</td>\n",
              "      <td>12.94636</td>\n",
              "      <td>-10.32437</td>\n",
              "      <td>-24.83777</td>\n",
              "      <td>8.76630</td>\n",
              "      <td>-0.92019</td>\n",
              "      <td>18.76548</td>\n",
              "      <td>...</td>\n",
              "      <td>5.66812</td>\n",
              "      <td>-19.68073</td>\n",
              "      <td>33.04964</td>\n",
              "      <td>42.87836</td>\n",
              "      <td>-9.90378</td>\n",
              "      <td>-32.22788</td>\n",
              "      <td>70.49388</td>\n",
              "      <td>12.04941</td>\n",
              "      <td>58.43453</td>\n",
              "      <td>26.92061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2001</td>\n",
              "      <td>50.95714</td>\n",
              "      <td>31.85602</td>\n",
              "      <td>55.81851</td>\n",
              "      <td>13.41693</td>\n",
              "      <td>-6.57898</td>\n",
              "      <td>-18.54940</td>\n",
              "      <td>-3.27872</td>\n",
              "      <td>-2.35035</td>\n",
              "      <td>16.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>3.03800</td>\n",
              "      <td>26.05866</td>\n",
              "      <td>-50.92779</td>\n",
              "      <td>10.93792</td>\n",
              "      <td>-0.07568</td>\n",
              "      <td>43.20130</td>\n",
              "      <td>-115.00698</td>\n",
              "      <td>-0.05859</td>\n",
              "      <td>39.67068</td>\n",
              "      <td>-0.66345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001</td>\n",
              "      <td>48.24750</td>\n",
              "      <td>-1.89837</td>\n",
              "      <td>36.29772</td>\n",
              "      <td>2.58776</td>\n",
              "      <td>0.97170</td>\n",
              "      <td>-26.21683</td>\n",
              "      <td>5.05097</td>\n",
              "      <td>-10.34124</td>\n",
              "      <td>3.55005</td>\n",
              "      <td>...</td>\n",
              "      <td>34.57337</td>\n",
              "      <td>-171.70734</td>\n",
              "      <td>-16.96705</td>\n",
              "      <td>-46.67617</td>\n",
              "      <td>-12.51516</td>\n",
              "      <td>82.58061</td>\n",
              "      <td>-72.08993</td>\n",
              "      <td>9.90558</td>\n",
              "      <td>199.62971</td>\n",
              "      <td>18.85382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2001</td>\n",
              "      <td>50.97020</td>\n",
              "      <td>42.20998</td>\n",
              "      <td>67.09964</td>\n",
              "      <td>8.46791</td>\n",
              "      <td>-15.85279</td>\n",
              "      <td>-16.81409</td>\n",
              "      <td>-12.48207</td>\n",
              "      <td>-9.37636</td>\n",
              "      <td>12.63699</td>\n",
              "      <td>...</td>\n",
              "      <td>9.92661</td>\n",
              "      <td>-55.95724</td>\n",
              "      <td>64.92712</td>\n",
              "      <td>-17.72522</td>\n",
              "      <td>-1.49237</td>\n",
              "      <td>-7.50035</td>\n",
              "      <td>51.76631</td>\n",
              "      <td>7.88713</td>\n",
              "      <td>55.66926</td>\n",
              "      <td>28.74903</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 91 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4275d364-aace-4267-9856-21f37b522bd8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4275d364-aace-4267-9856-21f37b522bd8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4275d364-aace-4267-9856-21f37b522bd8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "colnames = ['target'] + ['timbre_avg_' + str(i) for i in range(1, 13)] + ['timbre_covar_' + str(i) for i in range(1, 79)]\n",
        "df = pd.read_csv('YearPredictionMSD.txt', header=None, names=colnames)\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqj7q70Ql5lb"
      },
      "source": [
        "Write a function to load the dataset, e.g.,\n",
        "`trainYears, trainFeat, testYears, testFeat = loadMusicData(fname, addBias)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HO0rnbz9STFd"
      },
      "outputs": [],
      "source": [
        "def loadMusicData(data, addBias=True):\n",
        "  train_df = data[:463714]\n",
        "  test_df = data[463714:]\n",
        "  train_y = train_df['target'].values\n",
        "  train_x = train_df.iloc[:,1:].values\n",
        "  test_y = test_df['target'].values\n",
        "  test_x = test_df.iloc[:,1:].values\n",
        "  if addBias:\n",
        "    train_x = np.hstack((train_x, np.ones((train_x.shape[0],1))))\n",
        "    test_x = np.hstack((test_x, np.ones((test_x.shape[0],1))))\n",
        "  return train_y, train_x, test_y, test_x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iz0sr2dbmDpu"
      },
      "source": [
        "Write a function `mse = musicMSE(pred, gt)` where the inputs are the predicted year and the “ground truth” year from the dataset. The function computes the mean squared error(MSE) by rounding pred before computing the MSE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBi_cfQ4nGmY"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "def musicMSE(pred, gt):\n",
        "  pred = np.round(pred)\n",
        "  mse= mean_squared_error(pred, gt)\n",
        "  return mse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNpBvB08ojLl"
      },
      "source": [
        "Load the dataset and discuss its properties. \n",
        "1. What is the range of the variables? From 90 attributes, range of variables for timbre average is tighter than range of variables for timbre covariance. However, within each category itself, some attributes have wider range compared to others, in which we don't have further documentation to explain this event.\n",
        "2. How might you normalize them? Normalization can help to ensure that each variables contribute equally to the model. Since range of variables varies significantly accross 90 attributes, I will normalize the data using standardization technique (0 mean and unit std deviation for each attribute) where we can help to preserve importance of variables.\n",
        "3. What years are represented in the dataset? The dataset covers song released from 1922 to 2011 (90 years) with most common year of 2007.\n",
        "4. What will the test mean squared error (MSE) be if your classifier always outputs the most common year in the dataset? 190.08"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwHVPkNVoTmn",
        "outputId": "b4cbd585-1c94-4463-e76d-eeed27388731"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variable 1: range = 60\n",
            "Variable 2: range = 721\n",
            "Variable 3: range = 624\n",
            "Variable 4: range = 490\n",
            "Variable 5: range = 444\n",
            "Variable 6: range = 248\n",
            "Variable 7: range = 361\n",
            "Variable 8: range = 199\n",
            "Variable 9: range = 273\n",
            "Variable 10: range = 102\n",
            "Variable 11: range = 158\n",
            "Variable 12: range = 182\n",
            "Variable 13: range = 550\n",
            "Variable 14: range = 65727\n",
            "Variable 15: range = 36796\n",
            "Variable 16: range = 31832\n",
            "Variable 17: range = 19854\n",
            "Variable 18: range = 16826\n",
            "Variable 19: range = 11882\n",
            "Variable 20: range = 9564\n",
            "Variable 21: range = 9610\n",
            "Variable 22: range = 3707\n",
            "Variable 23: range = 6731\n",
            "Variable 24: range = 9808\n",
            "Variable 25: range = 4871\n",
            "Variable 26: range = 37870\n",
            "Variable 27: range = 26522\n",
            "Variable 28: range = 7735\n",
            "Variable 29: range = 6635\n",
            "Variable 30: range = 6669\n",
            "Variable 31: range = 6153\n",
            "Variable 32: range = 3471\n",
            "Variable 33: range = 4567\n",
            "Variable 34: range = 3921\n",
            "Variable 35: range = 2803\n",
            "Variable 36: range = 4208\n",
            "Variable 37: range = 22597\n",
            "Variable 38: range = 18155\n",
            "Variable 39: range = 15869\n",
            "Variable 40: range = 16243\n",
            "Variable 41: range = 8211\n",
            "Variable 42: range = 8068\n",
            "Variable 43: range = 6178\n",
            "Variable 44: range = 2904\n",
            "Variable 45: range = 1768\n",
            "Variable 46: range = 2529\n",
            "Variable 47: range = 23921\n",
            "Variable 48: range = 10960\n",
            "Variable 49: range = 12815\n",
            "Variable 50: range = 4412\n",
            "Variable 51: range = 3698\n",
            "Variable 52: range = 4207\n",
            "Variable 53: range = 5583\n",
            "Variable 54: range = 5100\n",
            "Variable 55: range = 2263\n",
            "Variable 56: range = 12109\n",
            "Variable 57: range = 17812\n",
            "Variable 58: range = 17732\n",
            "Variable 59: range = 9176\n",
            "Variable 60: range = 8190\n",
            "Variable 61: range = 3711\n",
            "Variable 62: range = 2370\n",
            "Variable 63: range = 1413\n",
            "Variable 64: range = 21394\n",
            "Variable 65: range = 10254\n",
            "Variable 66: range = 7344\n",
            "Variable 67: range = 3254\n",
            "Variable 68: range = 7345\n",
            "Variable 69: range = 7192\n",
            "Variable 70: range = 1720\n",
            "Variable 71: range = 11016\n",
            "Variable 72: range = 11695\n",
            "Variable 73: range = 10525\n",
            "Variable 74: range = 3453\n",
            "Variable 75: range = 2666\n",
            "Variable 76: range = 1459\n",
            "Variable 77: range = 19852\n",
            "Variable 78: range = 5449\n",
            "Variable 79: range = 13578\n",
            "Variable 80: range = 8490\n",
            "Variable 81: range = 1279\n",
            "Variable 82: range = 8872\n",
            "Variable 83: range = 5021\n",
            "Variable 84: range = 4832\n",
            "Variable 85: range = 602\n",
            "Variable 86: range = 6831\n",
            "Variable 87: range = 7154\n",
            "Variable 88: range = 699\n",
            "Variable 89: range = 14852\n",
            "Variable 90: range = 1059\n"
          ]
        }
      ],
      "source": [
        "# Range of variables\n",
        "var_ranges = np.ptp(df.iloc[:, 1:].values, axis=0)\n",
        "for i, var_range in enumerate(var_ranges):\n",
        "    print(\"Variable {}: range = {:.0f}\".format(i+1, var_range))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xcZrqpiyO0F"
      },
      "outputs": [],
      "source": [
        "#Normalize data using standardization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "def loadMusicData2(data, addBias=True):\n",
        "  train_df = data[:463714]\n",
        "  test_df = data[463714:]\n",
        "  train_y = train_df['target'].values\n",
        "  train_x = train_df.iloc[:,1:].values\n",
        "  test_y = test_df['target'].values\n",
        "  test_x = test_df.iloc[:,1:].values\n",
        "  train_x= scaler.fit_transform(train_x)\n",
        "  test_x= scaler.fit_transform(test_x)\n",
        "\n",
        "  if addBias:\n",
        "    train_x = np.hstack((train_x, np.ones((train_x.shape[0],1))))\n",
        "    test_x = np.hstack((test_x, np.ones((test_x.shape[0],1))))\n",
        "  \n",
        "\n",
        "  return train_y, train_x, test_y, test_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J88tbEW8y56c",
        "outputId": "1308fe50-6bb1-4b4d-c762-2003c848ce62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min years presented:  1922\n",
            "Max years presented:  2011\n",
            "Median years presented:  2002.0\n",
            "Most common year: 2007\n"
          ]
        }
      ],
      "source": [
        "#Years represented\n",
        "print('Min years presented: ', np.min(df['target']))\n",
        "print('Max years presented: ', np.max(df['target']))\n",
        "print('Median years presented: ', np.median(df['target']))\n",
        "\n",
        "from statistics import mode\n",
        "print('Most common year:', mode(df['target']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsuMY-B-6Rq8"
      },
      "outputs": [],
      "source": [
        "train_y, train_x, test_y, test_x = loadMusicData2(df, addBias=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgxWh8BG6E15",
        "outputId": "f8c0d5fa-e00a-46b7-caa6-883fd75e719d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "190.08239236117836"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#test MSE\n",
        "musicMSE(torch.full((test_y.shape[0],), 2007), test_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzi847OP89JV"
      },
      "source": [
        "##2. Classification\n",
        "This problem could have been posed as a classification problem by treating each year as a category. What would be the problems with this approach? Support your argument by analyzing a bar chart with the year as the x-axis and the number of examples for that year as the y-axis.\n",
        "\n",
        "As we can see from the chart, the distribution of train dataset is skewed to the left where majority of the data coming from the later years. If we treat this problem as a classification problem, the model will be biased and will be more likely to predict later years. Furthermore, classification means that the predicted data will be categorical values instead of continuous which can result in loss of information as repercussion. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "QByIY0eo3_uO",
        "outputId": "24d83955-fbe8-4d6e-e29c-7d13984e4f8d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEGCAYAAACkQqisAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAa9UlEQVR4nO3df5QdZZ3n8feHECSgmETabEzCNGqUjSghNCG7oysDa+jAcRJXZMEZ0wdZ4h7CHj3rzBJcz4Iie8AzAzOMwmwcsiT+Coi6yUAwExkcjrObHx0I+QmTJgRJiKQlQASUGPjuH/W0VDq3O7crXff27ft5nVPnVn3rx32q+pIvTz1PPaWIwMzMrIhj6l0AMzNrXE4iZmZWmJOImZkV5iRiZmaFOYmYmVlhx9a7ALV28sknR2tra72LYWbWUNavX/+riGjpHW+6JNLa2kpnZ2e9i2Fm1lAkPV0p7ttZZmZWmJOImZkV5iRiZmaFOYmYmVlhTiJmZlaYk4iZmRXmJGJmZoU5iZiZWWGlJRFJx0taK+kxSVskfSXF75L0lKQNaZqa4pJ0m6QuSRslTcsdq0PS9jR15OJnSdqU9rlNkso6HzMzO1yZT6y/BpwXES9LGgn8XNIDad2fR8S9vbafBUxO0znAHcA5ksYC1wFtQADrJS2PiBfSNlcCa4AVQDvwAGZmw0zrgvt/P7/zpovqWJJDlVYTiczLaXFkmvp7jeJsYEnabzUwWtJ44AJgVUTsS4ljFdCe1p0UEasjez3jEmBOWedjZmaHK7VNRNIISRuAvWSJYE1adWO6ZXWrpLek2ATgmdzuu1Ksv/iuCvFK5ZgnqVNSZ3d399GelpmZJaUmkYh4PSKmAhOB6ZJOB64FTgPOBsYC15RZhlSOhRHRFhFtLS2HDUJpZmYF1aR3VkS8CDwEtEfEnnTL6jXgfwPT02a7gUm53SamWH/xiRXiZmZWI2X2zmqRNDrNjwI+Bjye2jJIPanmAJvTLsuBuamX1gzgpYjYA6wEZkoaI2kMMBNYmdbtlzQjHWsusKys8zEzs8OV2TtrPLBY0giyZHVPRNwn6R8ltQACNgD/OW2/ArgQ6AJeBS4HiIh9km4A1qXtvhoR+9L8VcBdwCiyXlnumWVmVkOlJZGI2AicWSF+Xh/bBzC/j3WLgEUV4p3A6UdXUjMzK8pPrJuZWWFOImZmQ1TrgvsPechwKHISMTOzwpxEzMysMCcRMzMrzEnEzMwKcxIxM7PCnETMzKwwJxEzMyvMScTMzApzEjEzs8KcRMzMrDAnETMzK8xJxMzMCnMSMTOzwsp8KZWZmQ1AfsTenTddVMeSVM9JxMyswQylZOPbWWZmVpiTiJmZFeYkYmZmhZWWRCQdL2mtpMckbZH0lRQ/VdIaSV2S7pZ0XIq/JS13pfWtuWNdm+JPSLogF29PsS5JC8o6FzMzq6zMmshrwHkRcQYwFWiXNAO4Gbg1It4LvABckba/AnghxW9N2yFpCnAp8AGgHbhd0ghJI4BvArOAKcBlaVszM6uR0pJIZF5OiyPTFMB5wL0pvhiYk+Znp2XS+vMlKcWXRsRrEfEU0AVMT1NXROyIiAPA0rStmZnVSKltIqnGsAHYC6wCngRejIiDaZNdwIQ0PwF4BiCtfwl4Rz7ea5++4pXKMU9Sp6TO7u7uQTgzMzODkpNIRLweEVOBiWQ1h9PK/L5+yrEwItoioq2lpaUeRTAzG5Zq0jsrIl4EHgL+DTBaUs9DjhOB3Wl+NzAJIK1/O/B8Pt5rn77iZmZWI2X2zmqRNDrNjwI+BmwjSyYXp806gGVpfnlaJq3/x4iIFL809d46FZgMrAXWAZNTb6/jyBrfl5d1PmZmdrgyhz0ZDyxOvaiOAe6JiPskbQWWSvoa8ChwZ9r+TuDbkrqAfWRJgYjYIukeYCtwEJgfEa8DSLoaWAmMABZFxJYSz8fMzHopLYlExEbgzArxHWTtI73jvwU+1cexbgRurBBfAaw46sKamVkhfmLdzMwKcxIxM7PCnETMzKwwJxEzMyvMScTMzApzEjEzs8L8elwzswZXz9fluiZiZmaFOYmYmVlhTiJmZlaYk4iZmRXmJGJmZoU5iZiZWWFOImZmVpifEzEzq6P8Mx6NyDURMzMrzEnEzMwKcxIxM7PCnETMzKwwJxEzMyustCQiaZKkhyRtlbRF0udT/HpJuyVtSNOFuX2uldQl6QlJF+Ti7SnWJWlBLn6qpDUpfrek48o6HzMzO1yZNZGDwBcjYgowA5gvaUpad2tETE3TCoC07lLgA0A7cLukEZJGAN8EZgFTgMtyx7k5Heu9wAvAFSWej5mZ9VJaEomIPRHxSJr/NbANmNDPLrOBpRHxWkQ8BXQB09PUFRE7IuIAsBSYLUnAecC9af/FwJxSTsbMzCqqSZuIpFbgTGBNCl0taaOkRZLGpNgE4JncbrtSrK/4O4AXI+Jgr3il758nqVNSZ3d392CckpmZUYMkIumtwA+BL0TEfuAO4D3AVGAP8JdllyEiFkZEW0S0tbS0lP11ZmZNo9RhTySNJEsg342IHwFExHO59d8C7kuLu4FJud0nphh9xJ8HRks6NtVG8tubmVkNlJZEUpvFncC2iLglFx8fEXvS4ieAzWl+OfA9SbcA7wImA2sBAZMlnUqWJC4FPh0RIekh4GKydpIOYFlZ52NmNhjq+T70MpRZE/lD4DPAJkkbUuxLZL2rpgIB7AQ+BxARWyTdA2wl69k1PyJeB5B0NbASGAEsiogt6XjXAEslfQ14lCxpmZlZjZSWRCLi52S1iN5W9LPPjcCNFeIrKu0XETvIem+ZmVkd+Il1MzMrzEnEzMwKcxIxM7PCnETMzKwwJxEzMyvMScTMzApzEjEzs8KcRMzMrDAnETMzK6yqJCLpg2UXxMzMGk+1NZHbJa2VdJWkt5daIjMzaxhVJZGI+AjwJ2RDsq+X9D1JHyu1ZGZmNuRV3SYSEduBL5ONnPtR4DZJj0v6D2UVzszMhrZq20Q+JOlWsveknwd8PCL+dZq/tcTymZnZEFbtUPB/A/wd8KWI+E1PMCKelfTlUkpmZmZDXrVJ5CLgN7mXRB0DHB8Rr0bEt0srnZmZDWnVJpGfAv8eeDktnwD8A/BvyyiUmdlwkn8l7nBTbcP68RHRk0BI8yeUUyQzM2sU1SaRVyRN61mQdBbwm362NzOzJlDt7awvAD+Q9CzZe9P/FfAfyyqUmZk1hqqSSESsk3Qa8P4UeiIifldesczMrBEMZADGs4EPAdOAyyTN7W9jSZMkPSRpq6Qtkj6f4mMlrZK0PX2OSXFJuk1Sl6SNvW6fdaTtt0vqyMXPkrQp7XObJA3k5M3M7OhU+7Dht4G/AD5MlkzOBtqOsNtB4IsRMQWYAcyXNAVYADwYEZOBB9MywCxgcprmAXek7x4LXAecA0wHrutJPGmbK3P7tVdzPmZmNjiqbRNpA6ZERFR74IjYA+xJ87+WtA2YAMwGzk2bLQZ+RjaUymxgSfqO1ZJGSxqftl0VEfsAJK0C2iX9DDgpIlan+BJgDvBAtWU0M7OjU+3trM1kjemFSGoFzgTWAONSggH4JTAuzU8AnsnttivF+ovvqhCv9P3zJHVK6uzu7i56GmZm1ku1NZGTga2S1gKv9QQj4o+PtKOktwI/BL4QEfvzzRYREZKqrt0UFRELgYUAbW1tpX+fmVmzqDaJXF/k4JJGkiWQ70bEj1L4OUnjI2JPul21N8V3kw0132Niiu3mzdtfPfGfpfjECtubmVmNVPs+kX8CdgIj0/w64JH+9kk9pe4EtkXELblVy4GeHlYdwLJcfG7qpTUDeCnd9loJzJQ0JjWozwRWpnX7Jc1I3zU3dywzs7pqXXD/sB7upEdVNRFJV5L1mBoLvIes7eFvgfP72e0Pgc8AmyRtSLEvATcB90i6AngauCStWwFcCHQBrwKXA0TEPkk3kCUugK/2NLIDVwF3AaPIGtTdqG5mVkPV3s6aT9a9dg1kL6iS9M7+doiIn5M93V7JYckn9cqa38exFgGLKsQ7gdP7LbmZmZWm2t5Zr0XEgZ4FSccCbqA2M2ty1SaRf5L0JWBUerf6D4C/L69YZmbWCKpNIguAbmAT8Dmy9gu/0dDMrMlVOwDjG8C30mRmZgZU3zvrKSq0gUTEuwe9RGZm1jAGMnZWj+OBT5F19zUzsyZW7cOGz+em3RHxV8BF5RbNzMyGumpvZ03LLR5DVjOpthZjZmbDVLWJ4C9z8wfJhkC5pPKmZmbWLKrtnfVHZRfEzKyR5cfJ2nlT89ztr/Z21n/tb32vARbNzKxJDKR31tlkI+0CfBxYC2wvo1BmZtYYqk0iE4FpEfFrAEnXA/dHxJ+WVTAzMxv6qh32ZBxwILd8gDdfa2tmZk2q2prIEmCtpB+n5TnA4lJKZGZmDaPa3lk3SnoA+EgKXR4Rj5ZXLDOzoa8Z3lx4JNXezgI4AdgfEX8N7JJ0akllMjOzBlFVEpF0HXANcG0KjQS+U1ahzMysMVRbE/kE8MfAKwAR8SzwtrIKZWZmjaHaJHIgvQM9ACSdWF6RzMysUVSbRO6R9L+A0ZKuBH7KEV5QJWmRpL2SNudi10vaLWlDmi7MrbtWUpekJyRdkIu3p1iXpAW5+KmS1qT43ZKOq/akzcxscBwxiUgScDdwL/BD4P3A/4iIvznCrncB7RXit0bE1DStSN8xBbgU+EDa53ZJIySNAL4JzAKmAJelbQFuTsd6L/ACcMWRzsXMzAbXEbv4RkRIWhERHwRWVXvgiHhYUmuVm88GlkbEa8BTkrqA6WldV0TsAJC0FJgtaRtwHvDptM1i4HrgjmrLZ2ZmR6/a21mPSDp7kL7zakkb0+2uMSk2AXgmt82uFOsr/g7gxYg42CtekaR5kjoldXZ3dw/SaZiZWbVJ5BxgtaQnUwLYJGljge+7A3gPMBXYw6HvKSlNRCyMiLaIaGtpaanFV5qZNYV+b2dJOiUifgFc0N921YqI53LH/hZwX1rcDUzKbToxxegj/jxZI/+xqTaS397MzGrkSDWR/wMQEU8Dt0TE0/lpoF8maXxu8RNAT8+t5cClkt6SnoSfTDbU/DpgcuqJdRxZ4/vy1N34IeDitH8HsGyg5TEzs6NzpIZ15ebfPZADS/o+cC5wsqRdwHXAuZKmkj1vshP4HEBEbJF0D7CV7PW78yPi9XScq4GVwAhgUURsSV9xDbBU0teAR4E7B1I+M7MiesbLaqa3F/bnSEkk+pg/ooi4rEK4z3/oI+JG4MYK8RXAigrxHbzZg8vMzOrgSEnkDEn7yWoko9I8aTki4qRSS2dmZkNav0kkIkbUqiBmZtZ4qn0plZlZU8q/M8TtIIcbyPtEzMzMDuEkYmZmhTmJmJlZYU4iZmZWmJOImZkV5iRiZtZL64L7D+mVZX1zEjEzs8KcRMzMrDAnETMzK8xJxMzMCvOwJ2bW9Dy0SXGuiZiZWWFOImZmVpiTiJmZFeYkYmZmhblh3cyakp9IHxyuiZiZWWGlJRFJiyTtlbQ5FxsraZWk7elzTIpL0m2SuiRtlDQtt09H2n67pI5c/CxJm9I+t0lSWediZmaVlVkTuQto7xVbADwYEZOBB9MywCxgcprmAXdAlnSA64BzgOnAdT2JJ21zZW6/3t9lZmYlKy2JRMTDwL5e4dnA4jS/GJiTiy+JzGpgtKTxwAXAqojYFxEvAKuA9rTupIhYHREBLMkdy8zMaqTWbSLjImJPmv8lMC7NTwCeyW23K8X6i++qEK9I0jxJnZI6u7u7j+4MzMzs9+rWsJ5qEFGj71oYEW0R0dbS0lKLrzQzawq1TiLPpVtRpM+9Kb4bmJTbbmKK9RefWCFuZmY1VOskshzo6WHVASzLxeemXlozgJfSba+VwExJY1KD+kxgZVq3X9KM1Ctrbu5YZmYV+Y2Fg6+0hw0lfR84FzhZ0i6yXlY3AfdIugJ4Grgkbb4CuBDoAl4FLgeIiH2SbgDWpe2+GhE9jfVXkfUAGwU8kCYzM6uh0pJIRFzWx6rzK2wbwPw+jrMIWFQh3gmcfjRlNDOzo+Mn1s3MrDAnETMzK8wDMJrZsOU3FpbPNREzMyvMNREzs2Gk1rUv10TMzKwwJxEzMyvMScTMhhU/lV5bTiJmZlaYk4iZmRXmJGJmZoU5iZiZWWFOImZmVpiTiJmZFeYn1s2soXl8rPpyTcTMzApzEjEzs8KcRMzMrDC3iZhZw/GwJkOHayJmZlZYXZKIpJ2SNknaIKkzxcZKWiVpe/ock+KSdJukLkkbJU3LHacjbb9dUkc9zsXMrJnVsybyRxExNSLa0vIC4MGImAw8mJYBZgGT0zQPuAOypANcB5wDTAeu60k8ZmZWG0PpdtZsYHGaXwzMycWXRGY1MFrSeOACYFVE7IuIF4BVQHuNy2xm1tTqlUQC+AdJ6yXNS7FxEbEnzf8SGJfmJwDP5PbdlWJ9xc1sGPJ7QoamevXO+nBE7Jb0TmCVpMfzKyMiJMVgfVlKVPMATjnllME6rJlZ06tLTSQidqfPvcCPydo0nku3qUife9Pmu4FJud0nplhf8UrftzAi2iKiraWlZTBPxcysqdU8iUg6UdLbeuaBmcBmYDnQ08OqA1iW5pcDc1MvrRnAS+m210pgpqQxqUF9ZoqZ2TDQc/vKt7CGtnrczhoH/FhSz/d/LyJ+ImkdcI+kK4CngUvS9iuAC4Eu4FXgcoCI2CfpBmBd2u6rEbGvdqdhZmY1TyIRsQM4o0L8eeD8CvEA5vdxrEXAosEuo5mZVWcodfE1M7MG4yRiZmaFeQBGMxsy3IjeeFwTMTOzwpxEzMysMN/OMrNBV+17z/1+9MbnJGJmpetJFjtvusjtHsOMk4iZVa13zcHJwdwmYmZmhTmJmFm/PH6V9cdJxGwY6y8BODnYYHCbiFkDyrdFlHXsso5vw4uTiFkDGIwus9WuMxsIJxGzBucEYPXkJGI2RDk5WCNwEjEbItwWYY3IvbPMzKww10TM6si3rKzRuSZiVmN+PsOGE9dEzErQV5JwW4cNN04iZoPAjeLWrBo+iUhqB/4aGAH8XUTcVOciWQMoMhqtR601O1xDt4lIGgF8E5gFTAEukzSlvqWyocptEWaDr9FrItOBrojYASBpKTAb2FrXUhVU5nhIQ1Vf59xXTaG3gdQizGzwKSLqXYbCJF0MtEfEf0rLnwHOiYire203D5iXFt8PPHGEQ58M/GqQi9vIfD0O5etxKF+PQw3X6/EHEdHSO9joNZGqRMRCYGG120vqjIi2EovUUHw9DuXrcShfj0M12/Vo6DYRYDcwKbc8McXMzKwGGj2JrAMmSzpV0nHApcDyOpfJzKxpNPTtrIg4KOlqYCVZF99FEbFlEA5d9a2vJuHrcShfj0P5ehyqqa5HQzesm5lZfTX67SwzM6sjJxEzMyusaZKIpEWS9kranIudIen/Sdok6e8lnZTiH5O0PsXXSzovt89ZKd4l6TZJqsf5HK2BXI/c+lMkvSzpz3KxdklPpOuxoJbnMJgGej0kfSit25LWH5/iDf/7GOB/KyMlLU7xbZKuze0zXH4bkyQ9JGlr+nt/PsXHSlolaXv6HJPiSn/7LkkbJU3LHasjbb9dUke9zmlQRURTTMC/A6YBm3OxdcBH0/xngRvS/JnAu9L86cDu3D5rgRmAgAeAWfU+t7KvR279vcAPgD9LyyOAJ4F3A8cBjwFT6n1uNfh9HAtsBM5Iy+8ARgyX38cAr8WngaVp/gRgJ9A6zH4b44Fpaf5twL+QDbP0dWBBii8Abk7zF6a/vdJvYU2KjwV2pM8xaX5Mvc/vaKemqYlExMPAvl7h9wEPp/lVwCfTto9GxLMpvgUYJektksYDJ0XE6sh+FUuAOaUXvgQDuR4AkuYAT5Fdjx6/H3YmIg4APcPONJwBXo+ZwMaIeCzt+3xEvD5cfh8DvBYBnCjpWGAUcADYz/D6beyJiEfS/K+BbcAEsvNZnDZbzJt/69nAksisBkan38YFwKqI2BcRL5Bdx/banUk5miaJ9GELb/6wP8WhDy72+CTwSES8RvbD2ZVbtyvFhouK10PSW4FrgK/02n4C8ExuuSmuB9k/qCFppaRHJP23FB/Ov4++rsW9wCvAHuAXwF9ExD6G6W9DUivZnYo1wLiI2JNW/RIYl+b7OvdheU2aPYl8FrhK0nqyauqB/EpJHwBuBj5Xh7LVQ1/X43rg1oh4uV4Fq5O+rsexwIeBP0mfn5B0fn2KWDN9XYvpwOvAu4BTgS9Kend9iliu9D9TPwS+EBH78+tSzbMpn5do6IcNj1ZEPE52awJJ7wN+P9SrpInAj4G5EfFkCu8mG1qlx7AaZqWf63EOcLGkrwOjgTck/RZYzzAedqaf67ELeDgifpXWrSBrQ/gOw/T30c+1+DTwk4j4HbBX0j8DbWT/xz1sfhuSRpIlkO9GxI9S+DlJ4yNiT7pdtTfF+xqOaTdwbq/4z8osdy00dU1E0jvT5zHAl4G/TcujgfvJGs3+uWf7VHXdL2lG6nUzF1hW63KXpa/rEREfiYjWiGgF/gr4nxHxDYb5sDN9XQ+yERI+KOmE1BbwUWDrcP599HMtfgGcl9adSNaQ/DjD6LeR/pZ3Atsi4pbcquVATw+rDt78Wy8H5qZeWjOAl9JvYyUwU9KY1JNrZoo1tnq37NdqAr5Pdt/2d2T/J3kF8Hmynhb/AtzEm0/wf5nsPu+G3PTOtK4N2EzW8+QbPfs02jSQ69Frv+tJvbPS8oVp+yeB/17v86rV9QD+lKydYDPw9Vy84X8fA/xv5a1kPfa2kL3H58+H4W/jw2S3qjbm/j24kKxX3oPAduCnwNi0vchelvcksAloyx3rs0BXmi6v97kNxuRhT8zMrLCmvp1lZmZHx0nEzMwKcxIxM7PCnETMzKwwJxEzMyvMScSsZOl5gZ9LmpWLfUrST+pZLrPB4C6+ZjUg6XSy5ynOJBsp4lGgPd4cDWEgxzo2Ig4OchHNCnESMauRNGzMK8CJ6fMPyF41MBK4PiKWpQH+vp22Abg6Iv6vpHOBG4AXgNMi4n21Lb1ZZU4iZjWShgV5hGzwwvuALRHxnTTMzlqyWkoAb0TEbyVNBr4fEW0pidwPnB4RT9Wj/GaVNPUAjGa1FBGvSLobeBm4BPi43nxL5PHAKcCzwDckTSUbHTdf41jrBGJDjZOIWW29kSYBn4yIJ/IrJV0PPAecQdbx5be51a/UqIxmVXPvLLP6WAn8lzRCLJLOTPG3A3si4g3gM2SvmTUbspxEzOrjBrIG9Y2StqRlgNuBDkmPAafh2ocNcW5YNzOzwlwTMTOzwpxEzMysMCcRMzMrzEnEzMwKcxIxM7PCnETMzKwwJxEzMyvs/wNyUwnpXZgoDwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#plot year frequency from train dataset\n",
        "import matplotlib.pyplot as plt\n",
        "train_df = df[:463714]\n",
        "year_counts = train_df.iloc[:, 0].value_counts()\n",
        "plt.bar(year_counts.index, year_counts.values)\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiR5yP7wBxka"
      },
      "source": [
        "##3. Ridge regression\n",
        "\n",
        "* Implement stochastic gradient descent with mini-batches to minimize the loss and evaluate the train and test MSE.\n",
        "* Tune the learning rate and weight decay factor. \n",
        "* Show the train and test loss as a function of epochs, where the number of epochs should be chosen to ensure the train loss is minimized."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mini_batch_gradient_descent(X_train, y_train, X_test, y_test, batch_size=32, num_epochs=100, learning_rate=0.01, weight_decay_factor=0, loss_type='L2', weight_decay_form='none', momentum=False, momentum_factor=0.9):\n",
        "    num_features = X_train.shape[1]\n",
        "    num_batches = int(np.ceil(len(X_train) / batch_size))\n",
        "    weight = np.random.normal(size=num_features)\n",
        "    m = np.zeros_like(weight)\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "\n",
        "    def forward(X, w):\n",
        "        return np.dot(X, w)\n",
        "\n",
        "    def backward(X, error):\n",
        "        return np.dot(X.T, error)\n",
        "\n",
        "    def compute_gradient(X, y, y_pred, loss_type, w):\n",
        "      error = None\n",
        "      if loss_type == \"L2\":\n",
        "          error = 2*(y_pred - y)\n",
        "      elif loss_type == \"count\":\n",
        "          error = np.round(y_pred) - np.round(y)\n",
        "      elif loss_type == \"cross-entropy\":\n",
        "          error = y_pred - y\n",
        "      elif loss_type == 'L1':\n",
        "          error = np.sign(y_pred - y)\n",
        "      gradient = backward(X, error)\n",
        "      if weight_decay_form == 'L2':\n",
        "          gradient += weight_decay_factor * w\n",
        "      elif weight_decay_form == 'L1':\n",
        "          gradient += weight_decay_factor * np.sign(w)\n",
        "      return gradient, error\n",
        "\n",
        "    def compute_loss(y, y_pred, loss_type):\n",
        "        if loss_type == \"L2\":\n",
        "            return np.mean(np.square(y - y_pred))\n",
        "        elif loss_type == \"count\":\n",
        "            return np.mean(np.abs(np.round(y) - np.round(y_pred)))\n",
        "        elif loss_type == \"cross-entropy\":\n",
        "            y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)  # clip predictions\n",
        "            return -np.mean(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n",
        "        elif loss_type == 'L1':\n",
        "            return np.mean(np.abs(y - y_pred))\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Shuffle the data\n",
        "        perm = np.random.permutation(len(X_train))\n",
        "        X_train = X_train[perm]\n",
        "        y_train = y_train[perm]\n",
        "\n",
        "        # Mini-batch gradient descent\n",
        "        for i in range(num_batches):\n",
        "            start_idx = i * batch_size\n",
        "            end_idx = (i + 1) * batch_size\n",
        "            X_batch = X_train[start_idx:end_idx]\n",
        "            y_batch = y_train[start_idx:end_idx]\n",
        "\n",
        "            y_pred = forward(X_batch, weight)\n",
        "            gradient, error = compute_gradient(X_batch, y_batch, y_pred, loss_type, weight)\n",
        "\n",
        "            if momentum:\n",
        "              m = momentum_factor * m + (1 - momentum_factor) * gradient\n",
        "              weight -= learning_rate * m\n",
        "            else:\n",
        "                weight -= learning_rate * gradient.reshape(weight.shape)\n",
        "\n",
        "        # Compute train and test losses\n",
        "        y_train_pred = forward(X_train, weight)\n",
        "        train_loss = compute_loss(y_train, y_train_pred, loss_type)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        y_test_pred = forward(X_test, weight)\n",
        "        test_loss = compute_loss(y_test, y_test_pred, loss_type)\n",
        "        test_losses.append(test_loss)\n",
        "\n",
        "        print(\"Epoch:\", epoch+1, \"/100, Train loss:\", train_loss, \"Test loss:\", test_loss)\n",
        "\n",
        "    return weight, train_losses, test_losses\n"
      ],
      "metadata": {
        "id": "f7u12GIuw_jz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter tuning\n",
        "* Learning rate= 0.0001\n",
        "* Weight decay factor= 0.000001\n",
        "* Batch size=16\n",
        "* Number epochs=100\n",
        "* Loss type= L2\n",
        "* Weight decay form= None\n",
        "* No momentum\n",
        "\n"
      ],
      "metadata": {
        "id": "r27YeMIDlVMX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHLX_tNcbLWr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a06af480-dc33-4d58-9107-cfc92e6d03dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 /100, Train loss: 624963.180713875 Test loss: 625138.0103473006\n",
            "Epoch: 2 /100, Train loss: 97857.66303318129 Test loss: 97925.81077829158\n",
            "Epoch: 3 /100, Train loss: 15390.188771946448 Test loss: 15416.780255306494\n",
            "Epoch: 4 /100, Train loss: 2486.8592757104498 Test loss: 2496.911677788535\n",
            "Epoch: 5 /100, Train loss: 467.4612113147282 Test loss: 470.9598922685001\n",
            "Epoch: 6 /100, Train loss: 151.0942623581308 Test loss: 152.03108912762673\n",
            "Epoch: 7 /100, Train loss: 101.31728777739498 Test loss: 101.23873147484156\n",
            "Epoch: 8 /100, Train loss: 93.33338186243482 Test loss: 92.84897543534197\n",
            "Epoch: 9 /100, Train loss: 91.95288261521671 Test loss: 91.32435201466163\n",
            "Epoch: 10 /100, Train loss: 91.65240989342182 Test loss: 90.94364134070695\n",
            "Epoch: 11 /100, Train loss: 91.54546371715202 Test loss: 90.85178220653874\n",
            "Epoch: 12 /100, Train loss: 91.48660972435415 Test loss: 90.77269246155232\n",
            "Epoch: 13 /100, Train loss: 91.44185101300204 Test loss: 90.72315442537892\n",
            "Epoch: 14 /100, Train loss: 91.41146388173937 Test loss: 90.66273871301958\n",
            "Epoch: 15 /100, Train loss: 91.38407296727802 Test loss: 90.63468540335694\n",
            "Epoch: 16 /100, Train loss: 91.36351162707209 Test loss: 90.60386823859122\n",
            "Epoch: 17 /100, Train loss: 91.35088333298089 Test loss: 90.57178057055417\n",
            "Epoch: 18 /100, Train loss: 91.33610202779309 Test loss: 90.57385108850356\n",
            "Epoch: 19 /100, Train loss: 91.331685855484 Test loss: 90.51321590868942\n",
            "Epoch: 20 /100, Train loss: 91.31555835647853 Test loss: 90.57038175246883\n",
            "Epoch: 21 /100, Train loss: 91.30982356055364 Test loss: 90.57068303368594\n",
            "Epoch: 22 /100, Train loss: 91.30154763456397 Test loss: 90.52394642697077\n",
            "Epoch: 23 /100, Train loss: 91.29611999008142 Test loss: 90.54056231218554\n",
            "Epoch: 24 /100, Train loss: 91.29022161045707 Test loss: 90.5244842473938\n",
            "Epoch: 25 /100, Train loss: 91.2891767824722 Test loss: 90.54458094815195\n",
            "Epoch: 26 /100, Train loss: 91.28343764025442 Test loss: 90.51501563595373\n",
            "Epoch: 27 /100, Train loss: 91.28494585625707 Test loss: 90.495080573029\n",
            "Epoch: 28 /100, Train loss: 91.27769840837209 Test loss: 90.51750466118808\n",
            "Epoch: 29 /100, Train loss: 91.27576279390406 Test loss: 90.52074928289157\n",
            "Epoch: 30 /100, Train loss: 91.27483267101825 Test loss: 90.50689041821076\n",
            "Epoch: 31 /100, Train loss: 91.27169372969833 Test loss: 90.52552743338437\n",
            "Epoch: 32 /100, Train loss: 91.26970715995623 Test loss: 90.50023702290947\n",
            "Epoch: 33 /100, Train loss: 91.26965923409753 Test loss: 90.5039098597812\n",
            "Epoch: 34 /100, Train loss: 91.27006642944019 Test loss: 90.52351036918378\n",
            "Epoch: 35 /100, Train loss: 91.26623035334275 Test loss: 90.50997964955339\n",
            "Epoch: 36 /100, Train loss: 91.26469100179287 Test loss: 90.51143683211838\n",
            "Epoch: 37 /100, Train loss: 91.26506071654497 Test loss: 90.49472393305031\n",
            "Epoch: 38 /100, Train loss: 91.26507020718113 Test loss: 90.50934144657083\n",
            "Epoch: 39 /100, Train loss: 91.26985985600986 Test loss: 90.45922015050112\n",
            "Epoch: 40 /100, Train loss: 91.26365670629113 Test loss: 90.53531614828248\n",
            "Epoch: 41 /100, Train loss: 91.26155473089494 Test loss: 90.50269094919547\n",
            "Epoch: 42 /100, Train loss: 91.26121140828111 Test loss: 90.49399268595394\n",
            "Epoch: 43 /100, Train loss: 91.26201408485612 Test loss: 90.48095606629363\n",
            "Epoch: 44 /100, Train loss: 91.26774155214683 Test loss: 90.47309769991053\n",
            "Epoch: 45 /100, Train loss: 91.26132636196647 Test loss: 90.51008780416748\n",
            "Epoch: 46 /100, Train loss: 91.26181270042242 Test loss: 90.47394216586954\n",
            "Epoch: 47 /100, Train loss: 91.26050769608403 Test loss: 90.48562292776145\n",
            "Epoch: 48 /100, Train loss: 91.26184484489373 Test loss: 90.48863596412724\n",
            "Epoch: 49 /100, Train loss: 91.26295669309646 Test loss: 90.48605013747826\n",
            "Epoch: 50 /100, Train loss: 91.26051602847326 Test loss: 90.4790257109906\n",
            "Epoch: 51 /100, Train loss: 91.2597176259929 Test loss: 90.47528678808327\n",
            "Epoch: 52 /100, Train loss: 91.26041530037668 Test loss: 90.49822182342825\n",
            "Epoch: 53 /100, Train loss: 91.25897643886603 Test loss: 90.47685171426535\n",
            "Epoch: 54 /100, Train loss: 91.2593999889878 Test loss: 90.47221242277824\n",
            "Epoch: 55 /100, Train loss: 91.26157006704229 Test loss: 90.5219178492889\n",
            "Epoch: 56 /100, Train loss: 91.26915633203156 Test loss: 90.55339606028271\n",
            "Epoch: 57 /100, Train loss: 91.26388682341569 Test loss: 90.54205427543124\n",
            "Epoch: 58 /100, Train loss: 91.26146069405684 Test loss: 90.47806482305126\n",
            "Epoch: 59 /100, Train loss: 91.25993795396164 Test loss: 90.49611262472838\n",
            "Epoch: 60 /100, Train loss: 91.25912434466716 Test loss: 90.48939402953454\n",
            "Epoch: 61 /100, Train loss: 91.26211129896811 Test loss: 90.46921446720704\n",
            "Epoch: 62 /100, Train loss: 91.25990913934268 Test loss: 90.48794356139783\n",
            "Epoch: 63 /100, Train loss: 91.26032804982988 Test loss: 90.47585429139363\n",
            "Epoch: 64 /100, Train loss: 91.26014240305587 Test loss: 90.51474308078812\n",
            "Epoch: 65 /100, Train loss: 91.26098354131955 Test loss: 90.49862444336675\n",
            "Epoch: 66 /100, Train loss: 91.25804080605218 Test loss: 90.47507935137845\n",
            "Epoch: 67 /100, Train loss: 91.25970456799072 Test loss: 90.46103891746765\n",
            "Epoch: 68 /100, Train loss: 91.2590847505886 Test loss: 90.46456449707726\n",
            "Epoch: 69 /100, Train loss: 91.25793844583538 Test loss: 90.47901016478131\n",
            "Epoch: 70 /100, Train loss: 91.25907288416047 Test loss: 90.48153158953626\n",
            "Epoch: 71 /100, Train loss: 91.26741157075477 Test loss: 90.45631117186755\n",
            "Epoch: 72 /100, Train loss: 91.25822256476235 Test loss: 90.4740497632002\n",
            "Epoch: 73 /100, Train loss: 91.26065326467655 Test loss: 90.50058326696274\n",
            "Epoch: 74 /100, Train loss: 91.25738703236598 Test loss: 90.49239350853664\n",
            "Epoch: 75 /100, Train loss: 91.25796875588597 Test loss: 90.46794282063154\n",
            "Epoch: 76 /100, Train loss: 91.2588528490315 Test loss: 90.49060094342752\n",
            "Epoch: 77 /100, Train loss: 91.25940727962261 Test loss: 90.46112752164225\n",
            "Epoch: 78 /100, Train loss: 91.25783535578861 Test loss: 90.47162298747423\n",
            "Epoch: 79 /100, Train loss: 91.25935960141595 Test loss: 90.47210797007419\n",
            "Epoch: 80 /100, Train loss: 91.25783701071401 Test loss: 90.50797791230187\n",
            "Epoch: 81 /100, Train loss: 91.25862744759353 Test loss: 90.49581906698664\n",
            "Epoch: 82 /100, Train loss: 91.25942534642901 Test loss: 90.4960788803784\n",
            "Epoch: 83 /100, Train loss: 91.25754680866156 Test loss: 90.49571836401476\n",
            "Epoch: 84 /100, Train loss: 91.25898014578262 Test loss: 90.49205394044445\n",
            "Epoch: 85 /100, Train loss: 91.2591343619762 Test loss: 90.48517936811443\n",
            "Epoch: 86 /100, Train loss: 91.2585000417588 Test loss: 90.4983623152949\n",
            "Epoch: 87 /100, Train loss: 91.25769414765934 Test loss: 90.50239549455024\n",
            "Epoch: 88 /100, Train loss: 91.25901917496755 Test loss: 90.51232811322456\n",
            "Epoch: 89 /100, Train loss: 91.25917455914701 Test loss: 90.47946658121924\n",
            "Epoch: 90 /100, Train loss: 91.25989509793912 Test loss: 90.49180673849696\n",
            "Epoch: 91 /100, Train loss: 91.25707633229602 Test loss: 90.48957272066194\n",
            "Epoch: 92 /100, Train loss: 91.25784216534468 Test loss: 90.5008589963063\n",
            "Epoch: 93 /100, Train loss: 91.25778528979298 Test loss: 90.480831205761\n",
            "Epoch: 94 /100, Train loss: 91.25917244505365 Test loss: 90.49644720423825\n",
            "Epoch: 95 /100, Train loss: 91.25823764271534 Test loss: 90.4689723553126\n",
            "Epoch: 96 /100, Train loss: 91.25830598853327 Test loss: 90.48412936846277\n",
            "Epoch: 97 /100, Train loss: 91.26153805747664 Test loss: 90.52546896144155\n",
            "Epoch: 98 /100, Train loss: 91.26036635363548 Test loss: 90.48037120649612\n",
            "Epoch: 99 /100, Train loss: 91.25936610899693 Test loss: 90.51703228334115\n",
            "Epoch: 100 /100, Train loss: 91.25937077189994 Test loss: 90.52083183035846\n"
          ]
        }
      ],
      "source": [
        "w_ridge, train_loss_ridge, test_loss_ridge = mini_batch_gradient_descent(train_x, train_y, test_x, test_y, batch_size=16, num_epochs=100, learning_rate=0.000001, weight_decay_factor=0.000001, loss_type='L2', weight_decay_form=None, momentum=False, momentum_factor=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7olCs7GbNW5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "867d9c54-7634-4bfc-dab0-df26ae3bc506"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "num_epochs=100\n",
        "plt.plot(range(num_epochs), train_loss_ridge,'r', label=\"Train loss\")\n",
        "plt.plot(range(num_epochs), test_loss_ridge, 'bo',label=\"Test loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9ap9a_o1OGE"
      },
      "source": [
        "Pseudoinverse"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_loss(X, y, weight, loss_type):\n",
        "    if loss_type == 'L2':\n",
        "        loss = np.mean((np.dot(X, weight) - y) ** 2)\n",
        "    elif loss_type == 'count':\n",
        "        loss = np.mean(np.abs(np.dot(X, weight) - y))\n",
        "    elif loss_type == 'cross-entropy':\n",
        "        exp_term = np.exp(np.dot(X, weight))\n",
        "        loss = np.mean(np.log(1 + exp_term) - y * np.dot(X, weight))\n",
        "    return loss\n",
        "\n",
        "def pseudoinverse(train_x, train_y, test_x, test_y, alpha=0, loss_type='L2'):\n",
        "    pseudoinv= np.dot(np.linalg.inv(train_x.T.dot(train_x) + alpha*np.eye(train_x.shape[1])), train_x.T)\n",
        "    weight= np.dot(pseudoinv, train_y)\n",
        "    train_y_predict= np.dot(train_x, weight)\n",
        "    test_y_predict= np.dot(test_x, weight)\n",
        "\n",
        "    train_loss= compute_loss(train_x, train_y, weight, loss_type=loss_type)\n",
        "    test_loss= compute_loss(test_x, test_y,weight, loss_type=loss_type)\n",
        "  \n",
        "    print(f'Train loss: {train_loss:.4f}, Test loss: {test_loss:.4f}')\n",
        "    \n",
        "    return weight, train_loss, test_loss"
      ],
      "metadata": {
        "id": "ohY45Ph3pYrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_inverse, train_loss_inverse, test_loss_inverse = pseudoinverse(train_x, train_y, test_x, test_y, alpha=0, loss_type='L2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUVECvJdDX7I",
        "outputId": "9e8a337c-3aa9-4df9-8e4a-df3cf64e28a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 91.2564, Test loss: 90.4911\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Implement L1 weight decay"
      ],
      "metadata": {
        "id": "jL8oRaDeDY-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w_lasso, train_loss_lasso, test_loss_lasso = mini_batch_gradient_descent(train_x, train_y, test_x, test_y, batch_size=32, num_epochs=100, learning_rate=0.001, weight_decay_factor=0.01, loss_type='L1', weight_decay_form='L1', momentum=False, momentum_factor=None)\n",
        "num_epochs=100\n",
        "plt.plot(range(num_epochs), train_loss_lasso,'r', label=\"Train loss\")\n",
        "plt.plot(range(num_epochs), test_loss_lasso, 'bo',label=\"Test loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "erfbyKAdDhYL",
        "outputId": "cae54c28-5b9a-4084-8f51-03c64b47dce9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 /100, Train loss: 1536.306553485377 Test loss: 1536.416400145846\n",
            "Epoch: 2 /100, Train loss: 1072.737473486003 Test loss: 1072.8473201464722\n",
            "Epoch: 3 /100, Train loss: 609.1683934867181 Test loss: 609.278240147187\n",
            "Epoch: 4 /100, Train loss: 145.599313487433 Test loss: 145.7091601479019\n",
            "Epoch: 5 /100, Train loss: 6.521264511110533 Test loss: 6.531578838668304\n",
            "Epoch: 6 /100, Train loss: 6.527169428180771 Test loss: 6.53946709458782\n",
            "Epoch: 7 /100, Train loss: 6.523201857795742 Test loss: 6.538156065381862\n",
            "Epoch: 8 /100, Train loss: 6.529671262837253 Test loss: 6.549263502659853\n",
            "Epoch: 9 /100, Train loss: 6.531985370713384 Test loss: 6.54867165631753\n",
            "Epoch: 10 /100, Train loss: 6.532673044507494 Test loss: 6.540063269732217\n",
            "Epoch: 11 /100, Train loss: 6.52544955877054 Test loss: 6.547993547539347\n",
            "Epoch: 12 /100, Train loss: 6.524474138095963 Test loss: 6.531082363969998\n",
            "Epoch: 13 /100, Train loss: 6.523947435301993 Test loss: 6.535353409973815\n",
            "Epoch: 14 /100, Train loss: 6.534821036173326 Test loss: 6.547343612376445\n",
            "Epoch: 15 /100, Train loss: 6.5278723062866755 Test loss: 6.547001969483031\n",
            "Epoch: 16 /100, Train loss: 6.527654530030879 Test loss: 6.532025467176001\n",
            "Epoch: 17 /100, Train loss: 6.522671036248993 Test loss: 6.53617272853955\n",
            "Epoch: 18 /100, Train loss: 6.529510762201744 Test loss: 6.546419920424143\n",
            "Epoch: 19 /100, Train loss: 6.532312562935993 Test loss: 6.536005391433456\n",
            "Epoch: 20 /100, Train loss: 6.524624342365408 Test loss: 6.544070032944289\n",
            "Epoch: 21 /100, Train loss: 6.5298044764148315 Test loss: 6.534805039956663\n",
            "Epoch: 22 /100, Train loss: 6.53054773871653 Test loss: 6.552633794575227\n",
            "Epoch: 23 /100, Train loss: 6.54093681901643 Test loss: 6.556742978797632\n",
            "Epoch: 24 /100, Train loss: 6.532225707317792 Test loss: 6.546230823918224\n",
            "Epoch: 25 /100, Train loss: 6.523766436852328 Test loss: 6.542743651796658\n",
            "Epoch: 26 /100, Train loss: 6.526144748307243 Test loss: 6.535392589966958\n",
            "Epoch: 27 /100, Train loss: 6.5461276812411855 Test loss: 6.559239720602299\n",
            "Epoch: 28 /100, Train loss: 6.529829176126143 Test loss: 6.5544639463218894\n",
            "Epoch: 29 /100, Train loss: 6.528165225007889 Test loss: 6.54373555433218\n",
            "Epoch: 30 /100, Train loss: 6.53821472674421 Test loss: 6.548791321550305\n",
            "Epoch: 31 /100, Train loss: 6.52667990478574 Test loss: 6.543330640295879\n",
            "Epoch: 32 /100, Train loss: 6.528280103260865 Test loss: 6.544668147667727\n",
            "Epoch: 33 /100, Train loss: 6.530322152940453 Test loss: 6.53668696837022\n",
            "Epoch: 34 /100, Train loss: 6.524609180954439 Test loss: 6.542479050564343\n",
            "Epoch: 35 /100, Train loss: 6.5237914617152875 Test loss: 6.542111906577619\n",
            "Epoch: 36 /100, Train loss: 6.524248245783094 Test loss: 6.5447306079841345\n",
            "Epoch: 37 /100, Train loss: 6.524431650025453 Test loss: 6.531924943442748\n",
            "Epoch: 38 /100, Train loss: 6.54664805185549 Test loss: 6.566902983020231\n",
            "Epoch: 39 /100, Train loss: 6.529578109754065 Test loss: 6.5409521620619415\n",
            "Epoch: 40 /100, Train loss: 6.521355628745204 Test loss: 6.536480329239464\n",
            "Epoch: 41 /100, Train loss: 6.53036257342369 Test loss: 6.538326045005218\n",
            "Epoch: 42 /100, Train loss: 6.52722194931139 Test loss: 6.536077141015121\n",
            "Epoch: 43 /100, Train loss: 6.536823901509804 Test loss: 6.563201778860179\n",
            "Epoch: 44 /100, Train loss: 6.526941874999427 Test loss: 6.537749947335043\n",
            "Epoch: 45 /100, Train loss: 6.534206296331355 Test loss: 6.555909504170688\n",
            "Epoch: 46 /100, Train loss: 6.5298288761600665 Test loss: 6.5346880724036875\n",
            "Epoch: 47 /100, Train loss: 6.532470315798083 Test loss: 6.542435651079706\n",
            "Epoch: 48 /100, Train loss: 6.524587451339612 Test loss: 6.538802015229706\n",
            "Epoch: 49 /100, Train loss: 6.525738004560291 Test loss: 6.534960380512355\n",
            "Epoch: 50 /100, Train loss: 6.534309335611487 Test loss: 6.548712705043546\n",
            "Epoch: 51 /100, Train loss: 6.531276280921462 Test loss: 6.551691377283715\n",
            "Epoch: 52 /100, Train loss: 6.530212889918179 Test loss: 6.551292051838046\n",
            "Epoch: 53 /100, Train loss: 6.532656837859968 Test loss: 6.563321254828545\n",
            "Epoch: 54 /100, Train loss: 6.523952114847891 Test loss: 6.535392862108786\n",
            "Epoch: 55 /100, Train loss: 6.5255058627339775 Test loss: 6.547694340032199\n",
            "Epoch: 56 /100, Train loss: 6.530621835043945 Test loss: 6.547604522256289\n",
            "Epoch: 57 /100, Train loss: 6.527441041140531 Test loss: 6.54900116637921\n",
            "Epoch: 58 /100, Train loss: 6.528406841500781 Test loss: 6.551510080895147\n",
            "Epoch: 59 /100, Train loss: 6.549941823004871 Test loss: 6.576120411556123\n",
            "Epoch: 60 /100, Train loss: 6.526410379329039 Test loss: 6.547014057409693\n",
            "Epoch: 61 /100, Train loss: 6.52997788514445 Test loss: 6.55150527917345\n",
            "Epoch: 62 /100, Train loss: 6.524944669557199 Test loss: 6.539971159650241\n",
            "Epoch: 63 /100, Train loss: 6.524959141769278 Test loss: 6.548305229368472\n",
            "Epoch: 64 /100, Train loss: 6.53104150425512 Test loss: 6.543645319199324\n",
            "Epoch: 65 /100, Train loss: 6.527044207377514 Test loss: 6.54628214584056\n",
            "Epoch: 66 /100, Train loss: 6.5292962328678374 Test loss: 6.5421201342622295\n",
            "Epoch: 67 /100, Train loss: 6.530708990980971 Test loss: 6.54396358415813\n",
            "Epoch: 68 /100, Train loss: 6.5300776856114675 Test loss: 6.534522048086823\n",
            "Epoch: 69 /100, Train loss: 6.525101817545083 Test loss: 6.535111253457399\n",
            "Epoch: 70 /100, Train loss: 6.526113579762445 Test loss: 6.546584893585223\n",
            "Epoch: 71 /100, Train loss: 6.525557856799621 Test loss: 6.538868363181211\n",
            "Epoch: 72 /100, Train loss: 6.528521273873636 Test loss: 6.547772089564052\n",
            "Epoch: 73 /100, Train loss: 6.5478118969622825 Test loss: 6.551187073808305\n",
            "Epoch: 74 /100, Train loss: 6.5349808323557035 Test loss: 6.541874448987732\n",
            "Epoch: 75 /100, Train loss: 6.532269189509336 Test loss: 6.542377275194593\n",
            "Epoch: 76 /100, Train loss: 6.527480961492616 Test loss: 6.550618384530165\n",
            "Epoch: 77 /100, Train loss: 6.527693190181369 Test loss: 6.540820855810666\n",
            "Epoch: 78 /100, Train loss: 6.53313866597189 Test loss: 6.549048638210233\n",
            "Epoch: 79 /100, Train loss: 6.53157200590977 Test loss: 6.541950986403215\n",
            "Epoch: 80 /100, Train loss: 6.529946442114676 Test loss: 6.545798588322274\n",
            "Epoch: 81 /100, Train loss: 6.533099668652584 Test loss: 6.5544697922957535\n",
            "Epoch: 82 /100, Train loss: 6.53409631334603 Test loss: 6.536391019012623\n",
            "Epoch: 83 /100, Train loss: 6.530068525263113 Test loss: 6.547618355543713\n",
            "Epoch: 84 /100, Train loss: 6.53747030212108 Test loss: 6.545396861462552\n",
            "Epoch: 85 /100, Train loss: 6.526120492230301 Test loss: 6.53691148824907\n",
            "Epoch: 86 /100, Train loss: 6.5296954845523345 Test loss: 6.547127250260578\n",
            "Epoch: 87 /100, Train loss: 6.524893360143135 Test loss: 6.53921111925321\n",
            "Epoch: 88 /100, Train loss: 6.532956673204772 Test loss: 6.549818261371803\n",
            "Epoch: 89 /100, Train loss: 6.527999621555 Test loss: 6.547130553303107\n",
            "Epoch: 90 /100, Train loss: 6.525796740071573 Test loss: 6.543109548528259\n",
            "Epoch: 91 /100, Train loss: 6.531296055263275 Test loss: 6.54012290435606\n",
            "Epoch: 92 /100, Train loss: 6.522054428011477 Test loss: 6.534691445208033\n",
            "Epoch: 93 /100, Train loss: 6.5310699144542 Test loss: 6.546898801331889\n",
            "Epoch: 94 /100, Train loss: 6.528045069427458 Test loss: 6.54993922308933\n",
            "Epoch: 95 /100, Train loss: 6.532185742646947 Test loss: 6.533676049898339\n",
            "Epoch: 96 /100, Train loss: 6.526151822395917 Test loss: 6.5493884393866875\n",
            "Epoch: 97 /100, Train loss: 6.536495402890803 Test loss: 6.54805617034063\n",
            "Epoch: 98 /100, Train loss: 6.5311084695985455 Test loss: 6.556448666310454\n",
            "Epoch: 99 /100, Train loss: 6.534068001297718 Test loss: 6.555476128672672\n",
            "Epoch: 100 /100, Train loss: 6.533778397498369 Test loss: 6.544759138814189\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. Count Regression\n",
        "\\begin{align*}\n",
        "y_{pred} &= e^{w^T X}\\\\\n",
        "L(y, y_{pred}) &= e^{-y_{pred}} y_{pred}^y / y!\\\\\n",
        "&= -\\sum_{i=1}^{n}(y_i log(y_{pred,i}) - y_{pred,i})\\\\\n",
        "\\end{align*}"
      ],
      "metadata": {
        "id": "nCdeXttIDv23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_regression(X_train, y_train, X_test, y_test, batch_size=16, num_epochs=100, learning_rate=0.01, weight_decay_factor=0, loss_type='count', weight_decay_form='none', momentum=False, momentum_factor=0.9):\n",
        "    num_features = X_train.shape[1]\n",
        "    num_batches = int(np.ceil(len(X_train) / batch_size))\n",
        "    weight = np.random.normal(size=num_features)\n",
        "    m = 0\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "\n",
        "    def forward(X, w):\n",
        "      # Clip X * w to avoid overflow in the exponential function\n",
        "      Xw = np.clip(np.dot(X, w), -1000, 500)\n",
        "      # Apply the exponential function and replace any resulting inf or nan values\n",
        "      y_pred = np.where(np.isinf(np.exp(Xw)), 1e10, np.exp(np.clip(Xw, -500, 500)))\n",
        "      return y_pred\n",
        "\n",
        "    def backward(X, error):\n",
        "        return np.dot(X.T, error)\n",
        "\n",
        "    def compute_gradient(X, y, y_pred, loss_type, w):\n",
        "      error = None\n",
        "      if loss_type == \"L2\":\n",
        "          error = 2*(y_pred - y)\n",
        "      elif loss_type == \"count\":\n",
        "          # Clip y_pred to avoid overflow\n",
        "          y_pred_clipped = np.clip(y_pred, -100, None)\n",
        "          error = np.exp(-y_pred_clipped) * (y_pred - y)\n",
        "      elif loss_type == \"cross-entropy\":\n",
        "          error = y_pred - y\n",
        "\n",
        "      gradient = backward(X, error)\n",
        "      if weight_decay_form == 'L2':\n",
        "          gradient += weight_decay_factor * w\n",
        "      elif weight_decay_form == 'L1':\n",
        "          gradient += weight_decay_factor * np.sign(w)\n",
        "\n",
        "      return gradient, error\n",
        "\n",
        "\n",
        "    def compute_loss(y, y_pred, loss_type):\n",
        "      if loss_type == \"L2\":\n",
        "          return np.mean(np.square(y - y_pred))\n",
        "      elif loss_type == \"count\":\n",
        "          # Clip y_pred to avoid overflow\n",
        "          y_pred_clipped = np.clip(y_pred, -100, None)\n",
        "          return np.mean(np.exp(-y_pred_clipped) * np.square(y - y_pred))\n",
        "      elif loss_type == \"cross-entropy\":\n",
        "          y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)  # clip predictions\n",
        "          return -np.mean(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n",
        "      elif loss_type == 'L1':\n",
        "          return np.mean(np.abs(y - y_pred))\n",
        "      else:\n",
        "          raise ValueError(\"Invalid loss type: {}\".format(loss_type))\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Shuffle the data\n",
        "        perm = np.random.permutation(len(X_train))\n",
        "        X_train = X_train[perm]\n",
        "        y_train = y_train[perm]\n",
        "\n",
        "        # Mini-batch gradient descent\n",
        "        for i in range(num_batches):\n",
        "            start_idx = i * batch_size\n",
        "            end_idx = (i + 1) * batch_size\n",
        "            X_batch = X_train[start_idx:end_idx]\n",
        "            y_batch = y_train[start_idx:end_idx]\n",
        "\n",
        "            y_pred = forward(X_batch, weight)\n",
        "            gradient, error = compute_gradient(X_batch, y_batch, y_pred, loss_type, weight)\n",
        "\n",
        "            if momentum:\n",
        "                m = momentum_factor * m + (1 - momentum_factor) * gradient\n",
        "                weight -= learning_rate * m\n",
        "            else:\n",
        "                weight -= learning_rate * gradient\n",
        "\n",
        "        # Compute train and test losses\n",
        "        y_train_pred = forward(X_train, weight)\n",
        "        train_loss = compute_loss(y_train, y_train_pred, loss_type)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        y_test_pred = forward(X_test, weight)\n",
        "        test_loss = compute_loss(y_test, y_test_pred, loss_type)\n",
        "        test_losses.append(test_loss)\n",
        "\n",
        "        print(\"Epoch:\", epoch+1, \"/100, Train loss:\", train_loss, \"Test loss:\", test_loss)\n",
        "\n",
        "        # Check if the test loss has stopped decreasing\n",
        "        # if len(test_losses) >= 2 and test_losses[-1] >= test_losses[-2]:\n",
        "        #     print(\"Test loss has stopped decreasing. Stopping training.\")\n",
        "        #     break\n",
        "\n",
        "    return weight, train_losses, test_losses"
      ],
      "metadata": {
        "id": "cNIIYX9ZDrWg"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w, train_loss, test_loss= count_regression(train_x, train_y, test_x, test_y, batch_size=100, num_epochs=100, learning_rate=0.0000001, weight_decay_factor=0.001, loss_type='L2', weight_decay_form='L2', momentum=False, momentum_factor=0.9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "QxuLKLGkG1m3",
        "outputId": "1d56d8b6-9b51-46b2-fcd5-0b4d91f8b17e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-7241cbdda681>:41: RuntimeWarning: overflow encountered in square\n",
            "  return np.mean(np.square(y - y_pred))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 /100, Train loss: inf Test loss: inf\n",
            "Epoch: 2 /100, Train loss: inf Test loss: inf\n",
            "Epoch: 3 /100, Train loss: 3993666.588416567 Test loss: inf\n",
            "Epoch: 4 /100, Train loss: 3993666.588416567 Test loss: inf\n",
            "Epoch: 5 /100, Train loss: 3993666.588416567 Test loss: inf\n",
            "Epoch: 6 /100, Train loss: 3993666.588416567 Test loss: inf\n",
            "Epoch: 7 /100, Train loss: 3993666.588416567 Test loss: inf\n",
            "Epoch: 8 /100, Train loss: 3993666.588416567 Test loss: inf\n",
            "Epoch: 9 /100, Train loss: 3993666.588416567 Test loss: inf\n",
            "Epoch: 10 /100, Train loss: 3993666.588416567 Test loss: inf\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-e3d1e1a35bc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcount_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0000001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay_form\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-42-7241cbdda681>\u001b[0m in \u001b[0;36mcount_regression\u001b[0;34m(X_train, y_train, X_test, y_test, batch_size, num_epochs, learning_rate, weight_decay_factor, loss_type, weight_decay_form, momentum, momentum_factor)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# Shuffle the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mperm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6. Model comparison\n"
      ],
      "metadata": {
        "id": "m0zHKAuX2wv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fig, ax = plt.subplots(figsize=(8, 6))\n",
        "plt.hist(w_ridge, alpha=0.5, label='Ridge')\n",
        "plt.xlabel('Weight Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Weights - Ridge')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "iYbX4Db7jqkq",
        "outputId": "08e6653e-b37a-4194-8deb-390417fb2dd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(w_lasso, alpha=0.5, label='Lasso')\n",
        "plt.xlabel('Weight Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Weights - Lasso')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "kyqJJoVMEXKx",
        "outputId": "9970c72a-9a12-4080-9952-9b8bb4235d56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot a histogram of the weights for the ridge, lasso, and count regression models. Discuss\n",
        "how the weights differ**\n",
        "\n",
        "For Ridge and Lasso regression, the weight is quite similar. It means that the penalty term applied is not really significant to the model.\n",
        "\n",
        "Lasso regression gives significantly lower loss. It's important to note that Lasso is better at handling multicollinearity by performing feature selection and shrinking the cofficient towards zero and more effective in handling outliers. This might indicates our data has high sparsity or multicollinearity which resulting in Lasso performs better than Ridge.  However, since the weights are similar, it means that both Ridge and Lasso are able to capture relationships between the attributes and target varible."
      ],
      "metadata": {
        "id": "h8iRKY2fo7gS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discuss and compare the behaviors of the models. Are there certain periods (ranges of\n",
        "years) in which models perform better than others? Where are the largest errors across\n",
        "models. Did regularization help for some models but not others?**\n"
      ],
      "metadata": {
        "id": "AGiCpk5-u0Tx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate model L2\n",
        "periods = [(1920, 1940), (1940, 1960), (1960, 1980), (1980, 2000), (2000, 2020)]\n",
        "\n",
        "for period in periods:\n",
        "    train_mask = (train_y >= period[0]) & (train_y < period[1])\n",
        "    test_mask = (test_y >= period[1]) & (test_y < period[1]+20)\n",
        "    train_x_period, train_y_period = train_x[train_mask], train_y[train_mask]\n",
        "    test_x_period, test_y_period = test_x[test_mask], test_y[test_mask]\n",
        "\n",
        "    # Train the model using mini-batch gradient descent\n",
        "    weight, train_losses, test_losses = mini_batch_gradient_descent(train_x_period, train_y_period, test_x_period, test_y_period, num_epochs=100, learning_rate=0.01, weight_decay_factor=0.001, loss_type='L2', weight_decay_form='L2')\n",
        "    \n",
        "    # Evaluate the performance of the model on the test set for the period\n",
        "    y_pred = np.dot(test_x_period, weight)\n",
        "    mse = np.mean(np.square(test_y_period - y_pred))\n",
        "    print(\"Period:\", period, \"MSE:\", mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "7qZdHQWqvktT",
        "outputId": "01122edf-f388-42b5-c56f-2b6b4fb6c611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-4b56fadad6a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Train the model using mini-batch gradient descent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmini_batch_gradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay_form\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Evaluate the performance of the model on the test set for the period\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-c850454e92f8>\u001b[0m in \u001b[0;36mmini_batch_gradient_descent\u001b[0;34m(X_train, y_train, X_test, y_test, batch_size, num_epochs, learning_rate, weight_decay_factor, loss_type, weight_decay_form, momentum, momentum_factor)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0my_test_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mtest_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-c850454e92f8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(X, w)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shapes (336,91) and (90,) not aligned: 91 (dim 1) != 90 (dim 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[:, 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zo5wVyN-zdBe",
        "outputId": "7cc79ab1-e4f8-4d84-c90e-cb059089afe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         2001\n",
              "1         2001\n",
              "2         2001\n",
              "3         2001\n",
              "4         2001\n",
              "          ... \n",
              "515340    2006\n",
              "515341    2006\n",
              "515342    2006\n",
              "515343    2006\n",
              "515344    2005\n",
              "Name: target, Length: 515345, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate L2\n",
        "y_train_pred = np.dot(train_x, w_ridge)\n",
        "train_rmse = np.sqrt(np.mean(np.square(train_y - y_train_pred)))\n",
        "y_test_pred = np.dot(test_x, w_ridge)\n",
        "test_rmse = np.sqrt(np.mean(np.square(test_y - y_test_pred)))\n",
        "print(\"Train RMSE:\", train_rmse)\n",
        "print(\"Test RMSE:\", test_rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSWXN3PMvFAP",
        "outputId": "54ef64ad-d978-40a4-a367-9d82d67dfe75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train RMSE: 9.552927711558576\n",
            "Test RMSE: 9.512634607284436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate L1\n",
        "y_train_pred = np.dot(train_x, w_lasso)\n",
        "train_rmse = np.sqrt(np.mean(np.square(train_y - y_train_pred)))\n",
        "y_test_pred = np.dot(test_x, w_lasso)\n",
        "test_rmse = np.sqrt(np.mean(np.square(test_y - y_test_pred)))\n",
        "print(\"Train RMSE:\", train_rmse)\n",
        "print(\"Test RMSE:\", test_rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUi6LwWvqyY5",
        "outputId": "1b8f3d19-7c49-45a7-c601-efc17fcbd075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train RMSE: 9.870099705457289\n",
            "Test RMSE: 9.791397438648032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From RMSE above, L1 Lasso Regression gives larger error compared to Ridge."
      ],
      "metadata": {
        "id": "lMsyKIIZwOXL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 5 - Softmax Properties\n",
        "\n",
        "\n",
        "###1. Show that the softmax function is invariant to constant offsets to its input\n",
        "\n",
        "\\begin{align*}\n",
        "softmax(a+c1) &= \\frac{exp(a+c1)}{\\sum_{j=1}^{n}exp(a_j+c)} \\\\\n",
        "&= \\frac{exp(a)exp(c1)}{\\sum_{j=1}^{n}exp(a_j)exp(c)}\\\\\n",
        "&= \\frac{exp(a)}{\\sum_{j=1}^{n}exp(a_j)} \\times \\frac{exp(c1)}{\\sum_{j=1}^{n}exp(c)}{}\\\\\n",
        "&= softmax(a) \\times \\frac{exp(c1)}{n \\times exp(c)}{}\\\\\n",
        "&= softmax(a) \\times \\frac{exp(c1-c)}{n}\n",
        "\\end{align*}\n",
        "\n",
        "Since $\\frac{exp(c1-c)}{n}$ is a constant, it doesn't depend on $a$ and it's proven that softmax function is invariant to constant offset to its input.\n"
      ],
      "metadata": {
        "id": "Ri2DQfSOEA6H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.  Why is the observation that the softmax function is invariant to constant offsets to its input important when implementing it in a neural network?\n",
        "\n",
        "It's important that softmax function is invariant to constant offset to its input because it allows the model to be more robust to changes in input data. Adding or substracting a constant value from input data doesn't change the output of sofmax function and making the network to generalize better to new data that can improve reliability and accuracy."
      ],
      "metadata": {
        "id": "Pl2YQkyDNU7m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 6 - Implementing Softmax Classifier\n",
        "\n",
        "Write a function to load the data and the labels, which are returned as NumPy arrays."
      ],
      "metadata": {
        "id": "d7XFmHfPP_t3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXxYofx33qwQ",
        "outputId": "43882828-1810-42b8-94e9-ac348542dbc7"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def load_iris_data(train_file, test_file):\n",
        "    train_data = np.loadtxt(train_file)\n",
        "    test_data = np.loadtxt(test_file)\n",
        "    train_labels = train_data[:, 0].astype(int) -1\n",
        "    train_features = train_data[:, 1:]\n",
        "    test_labels = test_data[:, 0].astype(int) -1\n",
        "    test_features = test_data[:, 1:]\n",
        "\n",
        "    # Normalize the features to be between -1 and 1\n",
        "    mean_train = np.mean(train_features, axis=0)\n",
        "    std_train = np.std(train_features, axis=0)\n",
        "    train_features = (train_features - mean_train) / std_train\n",
        "    test_features = (test_features - mean_train) / std_train\n",
        "    return train_features, train_labels, test_features, test_labels\n",
        "\n",
        "iris_train = '/content/drive/MyDrive/Deep Learning/HW2/iris-train.txt'\n",
        "iris_test = '/content/drive/MyDrive/Deep Learning/HW2/iris-test.txt'\n",
        "\n",
        "train_features, train_labels, test_features, test_labels = load_iris_data(iris_train, iris_test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_features, train_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxrvhNu63P7s",
        "outputId": "7f0ad016-b061-48f3-88ba-a61ca6bcc3da"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(72, 2)\n",
            "(18, 2)\n",
            "(72,)\n",
            "(18,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Implementation & Evaluation\n",
        "\n",
        "* Use softmax loss with L2 weight decay regularization  \n",
        "*  Use stochastic gradient descent with mini batches and momentum to minimize softmax loss of single LNN (use environment's BLAS)\n",
        "* Loop over epochs and mini batches (not individual vector/ matrices)\n",
        "* 1000 epochs\n",
        "* Normalize feature between -1 and 1\n",
        "* Initial weight from Gaussian distribution\n",
        "\n",
        "*Cross entropy loss*\n",
        "\n",
        "$y_{i,j}$: true label for the $i$-th sample and $j$-th class\n",
        "\n",
        "$p_{i,j}$: predicted probability for the $i$-th sample and $j$-th class. \n",
        "$$ L = - \\frac{1}{N} \\sum_{i=1}^N \\sum_{j=1}^C y_{i,j} \\log(p_{i,j}) $$\n",
        "\n",
        "\n",
        "What is the best test accuracy your model achieved? What hyperparameters did you use?\n",
        "Would early stopping have helped improve accuracy on the test data?\n",
        "\n"
      ],
      "metadata": {
        "id": "TG4ZLs-d3nDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameters\n",
        "learning_rate = 0.01\n",
        "num_epochs = 1000\n",
        "batch_size = 32\n",
        "momentum = 0.9\n",
        "weight_decay = 0.001\n",
        "\n",
        "# Initialize weights\n",
        "num_features = X_train.shape[1]\n",
        "num_classes = len(np.unique(y_train))\n",
        "W = np.random.randn(num_features, num_classes) / np.sqrt(num_features)\n",
        "b = np.zeros(num_classes)"
      ],
      "metadata": {
        "id": "szvY0hUOuxIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_list = []\n",
        "test_loss_list = []\n",
        "train_accuracy_list = []\n",
        "test_accuracy_list = []\n",
        "\n",
        "# Define softmax function\n",
        "def softmax(z):\n",
        "    e_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
        "    return e_z / np.sum(e_z, axis=1, keepdims=True)\n",
        "\n",
        "# Define L2 regularization\n",
        "def L2_regularization(W, lambd):\n",
        "    return 0.5 * lambd * np.sum(W**2)\n",
        "\n",
        "# Define cross-entropy loss\n",
        "def cross_entropy_loss(y_pred, y_true):\n",
        "    num_samples = y_pred.shape[0]\n",
        "    correct_logprobs = -np.log(y_pred[range(num_samples), y_true])\n",
        "    data_loss = np.sum(correct_logprobs) / num_samples\n",
        "    return data_loss\n",
        "\n",
        "# Define gradient function\n",
        "def gradient(X, y, y_pred, W, b, lambd):\n",
        "    num_samples = X.shape[0]\n",
        "    dL_dy = y_pred\n",
        "    dL_dy[range(num_samples), y] -= 1\n",
        "    dL_dy /= num_samples\n",
        "    dW = X.T.dot(dL_dy) + lambd * W\n",
        "    db = np.sum(dL_dy, axis=0, keepdims=True)\n",
        "    return dW, db\n",
        "\n",
        "# Initialize momentum\n",
        "V_dW = np.zeros_like(W)\n",
        "V_db = np.zeros_like(b)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    # Shuffle training data\n",
        "    indices = np.random.permutation(X_train.shape[0])\n",
        "    X_train = X_train[indices]\n",
        "    y_train = y_train[indices]\n",
        "\n",
        "    # Mini-batch training\n",
        "    for i in range(0, X_train.shape[0], batch_size):\n",
        "        X_batch = X_train[i:i+batch_size]\n",
        "        y_batch = y_train[i:i+batch_size]\n",
        "\n",
        "        # Forward pass\n",
        "        z = X_batch.dot(W) + b\n",
        "        y_pred = softmax(z)\n",
        "\n",
        "        # Compute loss and regularization\n",
        "        loss = cross_entropy_loss(y_pred, y_batch)\n",
        "        reg_loss = loss + L2_regularization(W, weight_decay)\n",
        "\n",
        "        # Compute gradients\n",
        "        dW, db = gradient(X_batch, y_batch, y_pred, W, b, weight_decay)\n",
        "\n",
        "        # Update weights and bias using momentum\n",
        "        V_dW = momentum * V_dW - learning_rate * dW\n",
        "        V_db = momentum * V_db - learning_rate * db\n",
        "        W += V_dW\n",
        "        b = b.reshape(-1, 1) + V_db.reshape(-1, 1)\n",
        "        b = b.reshape(1, -1)\n",
        "\n",
        "    # Compute and store training loss\n",
        "    z_train = X_train.dot(W) + b\n",
        "    y_pred_train = softmax(z_train)\n",
        "    train_loss = cross_entropy_loss(y_pred_train, y_train)\n",
        "    train_loss_list.append(train_loss)\n",
        "\n",
        "    # Compute and store testing loss\n",
        "    z_test = X_test.dot(W) + b\n",
        "    y_pred_test = softmax(z_test)\n",
        "    test_loss = cross_entropy_loss(y_pred_test, y_test)\n",
        "    test_loss_list.append(test_loss)\n",
        "\n",
        "    # Compute and store training accuracy\n",
        "    y_pred_train_class = np.argmax(y_pred_train, axis=1)\n",
        "    train_accuracy = np.mean(y_pred_train_class == y_train)\n",
        "    train_accuracy_list.append(train_accuracy)\n",
        "\n",
        "    # Compute and store testing accuracy\n",
        "    y_pred_test_class = np.argmax(y_pred_test, axis=1)\n",
        "    test_accuracy = np.mean(y_pred_test_class == y_test)\n",
        "    test_accuracy_list.append(test_accuracy)\n"
      ],
      "metadata": {
        "id": "yfI5SFw0_cEV"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate plot:\n",
        "1. Cross-entropy loss during training as a function of number of epochs\n",
        "2. Mean per class accuracy as a function of training epoch"
      ],
      "metadata": {
        "id": "PG_iftItvTK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and testing loss\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_loss_list, label=\"Training Loss\")\n",
        "plt.plot(test_loss_list, label=\"Testing Loss\")\n",
        "plt.xlabel(\"Number of Training Epochs\")\n",
        "plt.ylabel(\"Cross-Entropy Loss\")\n",
        "plt.title(\"Training and Testing Loss\")\n",
        "plt.legend()\n",
        "\n",
        "# Plot training and testing accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracy_list, label=\"Training Accuracy\")\n",
        "plt.plot(test_accuracy_list, label=\"Testing Accuracy\")\n",
        "plt.xlabel(\"Number of Training Epochs\")\n",
        "plt.ylabel(\"Mean Per-Class Accuracy\")\n",
        "plt.title(\"Training and Testing Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "upmwOn0TunMm",
        "outputId": "95a889e6-8792-4a13-8017-e8d25773b63e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Best test accuracy', np.max(test_accuracy_list))\n",
        "print('Best train accuracy', np.max(train_accuracy_list))"
      ],
      "metadata": {
        "id": "rr3xg0SYurn9",
        "outputId": "90a1bd49-3ace-4a3d-cba3-9fc295363dcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best test accuracy 1.0\n",
            "Best train accuracy 0.9027777777777778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is the best test accuracy your model achieved?**\n",
        "Best test accuracy that the model has achieved is 100%. However, it is important to note that test data only consists of 18 data points which might result in this event. It is possible that the test set provided is easier to classify than the train set.\n",
        "\n",
        "**What hyperparameters did you use?**\n",
        "learning_rate = 0.01\n",
        "num_epochs = 1000\n",
        "batch_size = 32\n",
        "momentum = 0.9\n",
        "weight_decay = 0.001\n",
        "\n",
        "Would early stopping have helped improve accuracy on the test data?"
      ],
      "metadata": {
        "id": "ScQO9mf1v2c8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Omaj8tVJvIHb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}